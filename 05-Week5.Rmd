# Week 5: Regression II (Model Specification)

## Aims

1. Using multiple regressors and interaction terms in regression analysis for quantitative descriptive purposes with real data
2. Using simulation to instantiate how different properties of the data generating process alter or not metrics of goodness of fit

*<span style="color: red;">Should we request them to do descriptive statistics?</span>.*
*<span style="color: red;">Check: are all list numerals fine?</span>.*
*<span style="color: red;">Check: do all parameters in the interpretation texts fine?</span>.*


## Exercise: Context and Questions

Currently led by [Prof. Anke Tresch](https://forscenter.ch/staff/anke-tresch/), "[t]he Swiss Election Study (Selects) has been investigating the electoral behaviour of Swiss citizens in national elections since 1995. The project sheds light on the dynamics of the citizensâ€™ opinion formation as well as on the determinants of their political participation and voting choice for a specific candidate or party." See more [here](https://forscenter.ch/projects/selects/).

In this exercise, you will use data for the year 2019. You will use it to answer the following questions:

1. Do older voters have stronger right leaning preferences than younger ones?  age
2. Does that behavior change across sexes? sex
3. Does that behavior change depending on the main language spoken at the respondent's home? f20221
4. What about the interaction sex-age?
4. What about the interaction sex-language?
4. What about the interaction age-language?
4. What about the interaction sex-age-language?
4. Do right leaning preferences become stronger the older voters are?


## Getting the data first

```{r, include=FALSE}
# Load necessary libraries
library(swissdd)
library(dplyr)
library(tidyverse)
library(ggplot2)
library(BFS)
library(pxR)
library(ggridges)

```


Opening:
```{r}
# selects19 <- read.csv("~/Documents/0_IPZ/2023_2/Leemann-QuantMethods/QuantitativeMethods/Data/SELECTS 2019/1179_Selects2019_PES_Data_v1.1.0.csv", header = TRUE)
# 
# selects19 <- selects19 %>%
#   select(sex, age, matches("f15200"), f20221) %>%
#   filter(!is.na(selects19$sex) & !is.na(selects19$age) & !is.na(selects19$f15200) & !is.na(selects19$f20221))  # Remove rows where x or y is NA
# 
# selects19$f15200 <- as.numeric(selects19$f15200)
# 
# write.table(selects19, file = "~/Documents/0_IPZ/2023_2/Leemann-QuantMethods/QuantitativeMethods/QuantitativeMethods/Data/SELECTS 2019/data.csv", sep = ",", row.names = FALSE)

selects19 <- read.csv("~/Documents/0_IPZ/2023_2/Leemann-QuantMethods/QuantitativeMethods/QuantitativeMethods/Data/SELECTS 2019/data.csv", header = TRUE)
```

Labeling languages:
```{r}
selects19 <- selects19 %>%
  mutate(LanguageHome = case_when(
    f20221 == 1 ~ "German/Swiss German",
    f20221 == 2 ~ "French",
    f20221 == 3 ~ "Italian",
    f20221 == 4 ~ "Romansh",
    f20221 == 5 ~ "Other"))
```

Labeling sex:
```{r}
selects19 <- selects19 %>%
  mutate(Sex = case_when(
    sex == 1 ~ "Male",
    sex == 2 ~ "Female"))
```

Renaming political preferences:
```{r}
selects19 <- dplyr::rename(selects19, LeftToRight = f15200)

```

## Exercise: solution

**Note:** Remember that you can copy the code from one point to answer another point. Simply make the necessary adjustments.

### Real data

1. Graph age vs. political preferences. Use a linear regression line to describe how the variables relate to each other.

```{r}
#Means for Y and X
mean_LeftRight <- mean(selects19$LeftToRight, na.rm = TRUE)
mean_age <- mean(selects19$age, na.rm = TRUE)

# Create a scatter plot
ggplot(selects19, aes(x = age, y = LeftToRight)) +
  geom_point() +
  geom_smooth(method = "lm", formula = y ~ x, se = FALSE, color = "red") +  # Adding the regression line
  geom_hline(yintercept = mean_LeftRight, linetype = "dashed", color = "green") +  # Horizontal line at the mean of y
  geom_vline(xintercept = mean_age, linetype = "dashed", color = "orange") +  # Vertical line at the mean of x
  scale_y_continuous(
    limits = c(0, 10),
    breaks = seq(0, 10, by = 1)) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5)) +
  labs(
    x = "Age (years)",
    y = "Political Preferences (left to right)",
    title = "Scatter plot Age vs. Political Preferences"
  )

```



2. Since the political preferences as well as years are defined in discrete values, many values can overlap for the same pair` (preference, age)`. Use the `ggridges` package to see how do preferences distribute across different age values.
```{R}
# Assuming `data` is your dataframe with 'age', 'political_preference' and 'LeftToRight' as columns
# Replace `data`, `age`, `political_preference`, and `LeftToRight` with your actual dataframe and variable names.

ggplot(selects19, aes(x = age, y = as.factor(LeftToRight), fill = as.factor(LeftToRight))) +
  geom_density_ridges() +
  geom_smooth(data = selects19, aes(x = age, y = LeftToRight, group = 1), 
              method = "lm", formula = y ~ x, color = "red", se = FALSE) +
  geom_hline(yintercept = mean_LeftRight, linetype = "dashed", color = "green") +
  geom_vline(xintercept = mean_age, linetype = "dashed", color = "orange") +
  scale_fill_viridis_d() +
  theme_minimal() +
  theme(legend.position = "none") +
  labs(x = "Age (years)",
       y = "Political Preferences (left to right)",
       title = "Ridge Plot of Age by Number of Houses",
       fill = "factor(LeftToRight)")

```

3. Regress the political preferences on age. As we learnt in the exercises from last week, the regression with intercept fits data better in most cases: act accordingly. Report and interpret the parameters. Graph some of the main components of the regression output.

Write the regression here.
```{r}
#regression
result <- lm(LeftToRight ~ age, data = selects19)
summary(result)

```

Report and interpret the parameters here.
```{r}
coeffs<- coef(result)
cat('The beta value for', names(coeffs[1]), ' is ', round(unname(coeffs[1]), digits = 2), ' and for ', names(coeffs[2]), ' is ', round(unname(coeffs[2]), digits = 2), '. \n\nIt means that, given our model, an increase of one year in age across the Swiss citizens is associated with an average increase in the LeftToRight self-declared scale of ', round(unname(coeffs[2]), digits = 2), ' \'ideological units\'. Likewise, newborns can be expected to have an average ideological value of ',round(unname(coeffs[1]), digits = 2),', while 100 year old citizens can be expected to have an average ideological value of.', round(unname(coeffs[1]), digits = 2)+round(unname(coeffs[2]), digits = 2)*100)
```
Graph some of the main components of the regression output here.

```{r}
ggplot(selects19, aes(x = age, y = LeftToRight)) +  # Removed selects19$ from aes(), not necessary
  geom_point(size = 0.001) +
  geom_abline(intercept = unname(coeffs[1]),
              slope = 0, color = "gray", size = 1) +
  geom_text(aes(label = "Newborn",
                x = max(selects19$age)+10,
                y = 0.2+unname(coeffs[1])),
                hjust = 1, vjust = 0, color = "gray")+ 

  geom_abline(intercept = unname(coeffs[1]),
              slope = unname(coeffs[2]), color = "red", size = 1) +
  geom_text(aes(label = "Average individual over time",
                x = max(selects19$age)+10,
                y = 0.4+unname(coeffs[1]) + unname(coeffs[2]) * max(selects19$age)),
                hjust = 1, vjust = 0, color = "red") +

  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5)) +
  labs(
    x = "Age (years)",
    y = "Political Preferences (left to right)",
    title = "Lines Using Parameters from Regression"
  )
```


4. Now add the regressor `Sex` and do the same as in the previous point.
Write the regression here.
```{r}
#regression
result <- lm(LeftToRight ~ age + Sex, data = selects19)
summary(result)

```

Report and interpret the parameters here.
```{r}
coeffs<- coef(result)
cat('The beta value for', names(coeffs[1]), ' is ', round(unname(coeffs[1]), digits = 2), ' for ', names(coeffs[2]), ' is ', round(unname(coeffs[2]), digits = 2), ' and for ', names(coeffs[3]), ' is ', round(unname(coeffs[3]), digits = 2),
    
'. \n\nIt means that, given our model,  an increase of one year in age across the Swiss citizens is associated with an average increase in the LeftToRight self-declared scale of ', round(unname(coeffs[2]), digits = 2), ' \'ideological units\'. Likewise, newborns can be expected to have an average ideological value of ',round(unname(coeffs[1]), digits = 2),', while 100 year old female citizens can be expected to have an average ideological value of.', round(unname(coeffs[1]), digits = 2)+round(unname(coeffs[2]), digits = 2)*100, '. Similarly, for each of those scenarios, should the individual be a male, it can be expected to have an average of ', round(unname(coeffs[3]), digits = 2), ' ideological units higher than a female individual under the same statistical circumstances.')
```
Graph some of the main components of the regression output here.

```{r}
ggplot(selects19, aes(x = age, y = LeftToRight)) +  # Removed selects19$ from aes(), not necessary
  geom_point(size = 0.001) +
  geom_abline(intercept = unname(coeffs[1]),
              slope = 0, color = "gray", size = 1) +
  geom_text(aes(label = "Newborn female",
                x = max(selects19$age)+10,
                y = 0.2+unname(coeffs[1])),
                hjust = 1, vjust = 0, color = "gray")+ 

  geom_abline(intercept = unname(coeffs[1]),
              slope = unname(coeffs[2]), color = "red", size = 1) +
  geom_text(aes(label = "Female over time",
                x = max(selects19$age)+10,
                y = -0.8+unname(coeffs[1]) + unname(coeffs[2]) * max(selects19$age)),
                hjust = 1, vjust = 0, color = "red") +

  geom_abline(intercept = unname(coeffs[1])+unname(coeffs[3]),
              slope = unname(coeffs[2]), color = "orange", size = 1) +
  geom_text(aes(label = "Male over time (newborn bonus)",
                x = max(selects19$age)+10,
                y = 0.6+unname(coeffs[1])+unname(coeffs[3]) + unname(coeffs[2]) * max(selects19$age)+0.2),
                hjust = 1, vjust = 0, color = "orange") +

  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5)) +
  labs(
    x = "Age (years)",
    y = "Political Preferences (left to right)",
    title = "Lines Using Parameters from Regression"
  )

```

5. You now remember that average preferences can change not only across age and sex independently, but simultaneously: i.e., the average preferences across individuals in a same sex can change at different rates over time as well as begin from different points. Add the interaction  `Age` and `Sex` and do the same as in the previous point.


Write the regression here.
```{r}
#regression
result <- lm(LeftToRight ~ age * Sex, data = selects19)
summary(result)

```

Report and interpret the parameters here.
```{r}
coeffs<- coef(result)
cat('The beta value for', names(coeffs[1]), ' is ', round(unname(coeffs[1]), digits = 2), ' for ', names(coeffs[2]), ' is ', round(unname(coeffs[2]), digits = 2), ' for ', names(coeffs[3]), ' is ', round(unname(coeffs[3]), digits = 2),' and for ', names(coeffs[4]), ' is ', round(unname(coeffs[4]), digits = 2),
    
'. \n\nIt means that, given our model,  an increase of one year in age across the female Swiss citizens is associated with an average increase in the LeftToRight self-declared scale of ', round(unname(coeffs[2]), digits = 2), ' \'ideological units\'. Likewise, female newborns can be expected to have an average ideological value of ',round(unname(coeffs[1]), digits = 2),', while 100 year old female citizens can be expected to have an average ideological value of.', round(unname(coeffs[1]), digits = 2)+round(unname(coeffs[2]), digits = 2)*100, '. \n\nSimilarly, for each of those scenarios, should the individual be a male, it can be expected to have an average of ', round(unname(coeffs[3]), digits = 2), ' ideological units higher (i.e., self declare more right leaning) than a female individual under the same statistical circumstances. Finally, the rate at which right leaning prefferences increase over time is ', round(unname(coeffs[4]), digits = 2)*-1, ' lower than a female in the same statistical circumstances. Therefore, a 100 year old male can be expected to have an political preference of ', round(unname(coeffs[1]), digits = 2)+round(unname(coeffs[2]), digits = 2)*100+round(unname(coeffs[3]), digits = 2)+round(unname(coeffs[4]), digits = 2)*100)
```

Graph some of the main components of the regression output here.

```{r}
ggplot(selects19, aes(x = age, y = LeftToRight)) +
  geom_point(size = 0) +
  geom_abline(intercept = unname(coeffs[1]),
              slope = 0, color = "gray", size = 1) +
  geom_text(aes(label = "Newborn female",
                x = max(selects19$age)+10,
                y = -0.5+unname(coeffs[1])),
                hjust = 1, vjust = 0, color = "gray")+ 

  geom_abline(intercept = unname(coeffs[1]),
              slope = unname(coeffs[2]), color = "red", size = 1) +
  geom_text(aes(label = "Female over time",
                x = max(selects19$age)+10,
                y = -0.8+unname(coeffs[1]) + unname(coeffs[2]) * max(selects19$age)),
                hjust = 1, vjust = 0, color = "red") +

  geom_abline(intercept = unname(coeffs[1])+unname(coeffs[3]),
              slope = unname(coeffs[2])+unname(coeffs[4]), color = "orange", size = 1) +
  geom_text(aes(label = "Male over time (newborn bonus+Î”slope)",
                x = max(selects19$age)+10,
                y = 0.45+unname(coeffs[1])+unname(coeffs[3]) + (unname(coeffs[2])+unname(coeffs[4])) * max(selects19$age)),
                hjust = 1, vjust = 0, color = "orange") +
  
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5)) +
  labs(
    x = "Age (years)",
    y = "Political Preferences (left to right)",
    title = "Lines Using Parameters from Regression"
  )
```

6. Following the same logic as in the previous point, you now add the `LanguageHome` categorical variable with the corresponding interactions. Do the same as in the previous point.

Write the regression here.
```{r}
#regression
result <- lm(LeftToRight ~ age * Sex * LanguageHome, data = selects19)
summary(result)

```

Report and interpret the parameters here.
```{r}
coeffs <- coef(result)
cat('Interpreting a regression with ever more interactions is exponentially harder! Thus, find below some few cases aimed at signaling the general logic in the interpretation.',
    
'\n\nAn increase of one year in age across the female Swiss citizens is associated with an average increase in the LeftToRight self-declared scale of ', round(unname(coeffs[2]), digits = 2), ' \'ideological units\'. Likewise, female newborns whose household speaks mainly in French can be expected to have an average ideological value of ',round(unname(coeffs[1]), digits = 2),', while a 100 year old female citizens whose household speaks mainly in French can be expected to have an average ideological value of.', round(unname(coeffs[1]), digits = 2)+round(unname(coeffs[2]), digits = 2)*100, 

'.\n\nSimilarly, should one observe a random 100 year old male individual whose household speaks mainly in German, we can expected him have an average of ', round(unname(coeffs[2]), digits = 2)*100+round(unname(coeffs[3]), digits = 2)+round(unname(coeffs[8]), digits = 2)*100+round(unname(coeffs[9]), digits = 2)*100+round(unname(coeffs[13]), digits = 2)+round(unname(coeffs[17]), digits = 2)*100, ' ideological units higher than a female newborn whose household speaks mainly in French. Consequently, the expected ideological value for the former would be of ', round(unname(coeffs[1]), digits = 2)+round(unname(coeffs[2]), digits = 2)*100+round(unname(coeffs[3]), digits = 2)+round(unname(coeffs[8]), digits = 2)*100+round(unname(coeffs[9]), digits = 2)*100+round(unname(coeffs[13]), digits = 2)+round(unname(coeffs[17]), digits = 2)*100)
```
Graph some of the main components of the regression output here.

```{r}
ggplot(selects19, aes(x = age, y = LeftToRight)) +  # Removed selects19$ from aes(), not necessary
  geom_point(size = 0) +
  geom_abline(intercept = unname(coeffs[1]),
              slope = 0, color = "gray", size = 1) +
  geom_text(aes(label = "Newborn female French speaking household",
                x = max(selects19$age)+10,
                y = 0.1+unname(coeffs[1])),
                hjust = 1, vjust = 0, color = "gray")+ 

  geom_abline(intercept = unname(coeffs[1]),
              slope = unname(coeffs[2]), color = "red", size = 1) +
  geom_text(aes(label = "Female French speaking household over time",
                x = max(selects19$age)+10,
                y = -1.6+unname(coeffs[1]) + unname(coeffs[2]) * max(selects19$age)),
                hjust = 1, vjust = 0, color = "red") +

  geom_abline(intercept = unname(coeffs[1])+unname(coeffs[3]),
              slope = unname(coeffs[2])+unname(coeffs[8]), color = "orange", size = 1) +
  geom_text(aes(label = "Male French household over time (newborn bonus+Î”slope)",
                x = max(selects19$age)+10,
                y = 0.4+unname(coeffs[1])+unname(coeffs[3]) + (unname(coeffs[2])+unname(coeffs[8])) * max(selects19$age)+0.2),
                hjust = 1, vjust = 0, color = "orange") +
  
  geom_abline(intercept = unname(coeffs[1])+unname(coeffs[3])+unname(coeffs[13]),
              slope = unname(coeffs[2])+unname(coeffs[8])+unname(coeffs[17]), color = "purple", size = 1) +
  geom_text(aes(label = "Male German household over time (newborn & ling. bonus+Î”slope)",
                x = max(selects19$age)+10,
                y = 1.2+unname(coeffs[1])+unname(coeffs[3])+unname(coeffs[13]) + (unname(coeffs[2])+unname(coeffs[8])+unname(coeffs[17])) * max(selects19$age)+0.2),
                hjust = 1, vjust = 0, color = "purple") +  
  # geom_abline(intercept = unname(coeffs[1])+unname(coeffs[3]),
  #             slope = unname(coeffs[2])+unname(coeffs[4]), color = "blue", size = 1) +
  # geom_text(aes(label = "Int.(fem)+Male+Age*Male",
  #               x = max(selects19$age)+10,
  #               y = 0.3+unname(coeffs[1])+unname(coeffs[3]) + (unname(coeffs[2])+unname(coeffs[4])) * max(selects19$age)+0.2),
  #               hjust = 1, vjust = 0, color = "blue") +
  
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5)) +
  labs(
    x = "Age (years)",
    y = "Political Preferences (left to right)",
    title = "Lines Using Parameters from Regression"
  )
```

*<span style="color: red;">Ojo: Check that interpretations have the right parameters!</span>.*



## Interactive Line Plot

*<span style="color: red;">Should we exploit this here or somewhere else? I can make it work in R, but not in the book yet. If needed, I can check it out.</span>.*


```{r}
# # Example data frame
# data <- data.frame(
#   x = rnorm(100),
#   y = rnorm(100)
# )
# 
# # Shiny server function
# server <- function(input, output) {
#   output$scatterPlot <- renderPlot({
#     ggplot(data, aes(x = x, y = y)) +  # Ensure 'data' is your data frame
#       geom_point(size = 0) +
#       geom_abline(intercept = input$intercept, slope = input$slope, color = "red", size = 1)
#   })
# }
# 
# # Example data frame
# data <- data.frame(
#   x = rnorm(100),
#   y = rnorm(100)
# )
# 
# # Shiny server function
# server <- function(input, output) {
#   output$scatterPlot <- renderPlot({
#     ggplot(data, aes(x = x, y = y)) +  # Ensure 'data' is your data frame
#       geom_point(size = 0) +
#       geom_abline(intercept = input$intercept, slope = input$slope, color = "red", size = 1)
#   })
# }
# 
# update.packages(ask = FALSE)
# 
# 
# library(shiny)
# library(ggplot2)
# 
# ui <- fluidPage(
#   titlePanel("Interactive Line Plot"),
#   sidebarLayout(
#     sidebarPanel(
#       sliderInput("intercept", "Intercept:", min = -10, max = 10, value = 0),
#       sliderInput("slope", "Slope:", min = -10, max = 10, value = 1)
#     ),
#     mainPanel(
#       plotOutput("scatterPlot")
#     )
#   )
# )
# 
# server <- function(input, output) {
#   output$scatterPlot <- renderPlot({
#     ggplot(data, aes(x = x, y = y)) +
#       geom_point(size = 0) +
#       geom_abline(intercept = input$intercept, slope = input$slope, color = "red", size = 1)
#   })
# }
# 
# shinyApp(ui = ui, server = server)
```

### Simulated data

1. In order to see the logic behind the $R^2$, first estimate the linear regression of `LeftToRight` on `Age`. Generate the variable `predicted_LeftToRight` with the generated parameters using [`predict()`](https://www.statology.org/r-lm-predict/) from the point 3 of the previous section (i.e., the one using real data).Generate the graph `predicted_LeftToRight` vs `Age`.

Report the regression here.
```{r}
result <- lm(LeftToRight ~ age, data = selects19)
selects19$predicted_LeftToRight <- predict(result)

coeffs1 <- coef(result)
rsq_sd1 <- summary(result)$r.squared
cat('The R2 is: ', rsq_sd1, '\n\nIntercept:',unname(coeffs1[1]), '\n\nSlope:', unname(coeffs1[2]))
```

Report the graph here.
```{r}
# Calculate means for Y and X
mean_LeftRight <- mean(selects19$LeftToRight, na.rm = TRUE)
mean_age <- mean(selects19$age, na.rm = TRUE)

# Create a scatter plot
ggplot(selects19, aes(x = age, y = predicted_LeftToRight)) +
  geom_smooth(method = "lm", formula = y ~ x, se = FALSE, color = "red") +  # Adding the regression line
  geom_hline(yintercept = mean_LeftRight, linetype = "dashed", color = "green") +  # Horizontal line at the mean of y
  geom_vline(xintercept = mean_age, linetype = "dashed", color = "orange") +  # Vertical line at the mean of x
  scale_y_continuous(
    limits = c(0, 10),
    breaks = seq(0, 10, by = 1)  
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5), # Center the plot title
    panel.grid.major.y = element_line(color = "grey80", size = 0.5), # Style for major Y grid lines
    panel.grid.minor.y = element_blank() # Remove minor Y grid lines
  ) +
  labs(
    x = "Age (years)",
    y = "Political Preferences (left to right)",
    title = "Scatter plot Age vs. Political Preferences (determ. sim.)"
  )


```

2. Now generate the normally distributed residuals with mean zero and the same variance as the residuals of the model from the previous point.
```{r}
# Calculate the variance of the residuals
selects19$residual <- resid(result)
residual_sd <- sqrt(var(resid(result)))

# Set the seed for reproducibility
set.seed(0)
selects19$NormResiduals1 <- rnorm(nrow(selects19), mean = 0, sd = residual_sd)

```

3. Simulate new data using both the deterministic  (i.e., the the parameters estimated immediately above) and stochastic component (i.e., the residuals form the previous point). Graph the simulated data.
```{r}

selects19$Sim_LeftToRight_Det_Stoch <- selects19$predicted_LeftToRight + selects19$NormResiduals1

#Means for Y and X
mean_LeftRight <- mean(selects19$Sim_LeftToRight_Det_Stoch, na.rm = TRUE)
mean_age <- mean(selects19$age, na.rm = TRUE)

# Create a scatter plot
ggplot(selects19, aes(x = age, y = Sim_LeftToRight_Det_Stoch)) +
  geom_point(size = 0) +
  geom_smooth(method = "lm", formula = y ~ x, se = FALSE, color = "red") +  # Adding the regression line
  geom_hline(yintercept = mean_LeftRight, linetype = "dashed", color = "green") +  # Horizontal line at the mean of y
  geom_vline(xintercept = mean_age, linetype = "dashed", color = "orange") +  # Vertical line at the mean of x
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5)) +
  scale_y_continuous(
    limits = c(0, 10),
    breaks = seq(0, 10, by = 1)) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5), # Center the plot title
    panel.grid.major.y = element_line(color = "grey80", size = 0.5), # Style for major Y grid lines
    panel.grid.minor.y = element_blank() # Remove minor Y grid lines
  ) +
  labs(
    x = "Age (years)",
    y = "Simulation: Political Preferences (left to right)",
    title = "Scatter plot Age vs. Political Preferences \n(determ.& stoch. sim.)"
  )

```

4. Now, estimate the regression between the real `age` and simulated `Sim_LeftToRight_Det_Stoch`. Once you do that, generate the $R^2$ for the model.

```{r}
result <- lm(LeftToRight ~ age, data = selects19)
rsq_sd1 <- summary(result)$r.squared
cat('The R2 is: ', rsq_sd1)

```

5. Repeat the previous three points but use half the standard deviation of the model of point 1. Is the $R^2$ lower now? Why? See [this](https://en.wikipedia.org/wiki/Coefficient_of_determination) entry to understand the intuition: pay special attention to the graph with the red and blue squares.

Generate the residuals here. 
```{r}
# Set the seed for reproducibility
set.seed(0)
selects19$NormResiduals10 <- rnorm(nrow(selects19), mean = 0, sd = residual_sd*0.1)

```

Simulate new data and graph it here.
```{r}
selects19$Sim_LeftToRight_Det_Stoch_sd10 <- selects19$predicted_LeftToRight + selects19$NormResiduals10

#Means for Y and X
mean_LeftRight <- mean(selects19$Sim_LeftToRight_Det_Stoch_sd10, na.rm = TRUE)
mean_age <- mean(selects19$age, na.rm = TRUE)

# Create a scatter plot
ggplot(selects19, aes(x = age, y = Sim_LeftToRight_Det_Stoch_sd10)) +
  geom_point(size = 0) +
  geom_smooth(method = "lm", formula = y ~ x, se = FALSE, color = "red") +  # Adding the regression line
  geom_hline(yintercept = mean_LeftRight, linetype = "dashed", color = "green") +  # Horizontal line at the mean of y
  geom_vline(xintercept = mean_age, linetype = "dashed", color = "orange") +  # Vertical line at the mean of x
  scale_y_continuous(
    limits = c(0, 10),
    breaks = seq(0, 10, by = 1)) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5)) +
  labs(
    x = "Age (years)",
    y = "Simulated data (half sd): Political Preferences (left to right)",
    title = "Scatter plot Age vs. Political Preferences"
  )

```


Report the new $R^2$ here:
```{r}
result <- lm(Sim_LeftToRight_Det_Stoch_sd10 ~ age, data = selects19)
rsq_sd10 <- summary(result)$r.squared
cat('The R2 is: ', rsq_sd10)

```

6. Repeat the previous point but use a hundredth the standard deviation of the model of point 1. Is the $R^2$ lower now? Why?

Generate the residuals here. 
```{r}
# Set the seed for reproducibility
set.seed(0)
selects19$NormResiduals100 <- rnorm(nrow(selects19), mean = 0, sd = residual_sd*0.01)

```

Simulate new data and graph it here.
```{r}
selects19$Sim_LeftToRight_Det_Stoch_hsd <- selects19$predicted_LeftToRight + selects19$NormResiduals100

#Means for Y and X
mean_LeftRight <- mean(selects19$Sim_LeftToRight_Det_Stoch_hsd, na.rm = TRUE)
mean_age <- mean(selects19$age, na.rm = TRUE)

# Create a scatter plot
ggplot(selects19, aes(x = age, y = Sim_LeftToRight_Det_Stoch_hsd)) +
  geom_point(size = 0) +
  geom_smooth(method = "lm", formula = y ~ x, se = FALSE, color = "red") +  # Adding the regression line
  geom_hline(yintercept = mean_LeftRight, linetype = "dashed", color = "green") +  # Horizontal line at the mean of y
  geom_vline(xintercept = mean_age, linetype = "dashed", color = "orange") +  # Vertical line at the mean of x
  scale_y_continuous(
    limits = c(0, 10),
    breaks = seq(0, 10, by = 1)) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5)) +
  labs(
    x = "Age (years)",
    y = "Simulated data (half sd): Political Preferences (left to right)",
    title = "Scatter plot Age vs. Political Preferences"
  )

```


Report the new $R^2$ here:
```{r}
result <- lm(Sim_LeftToRight_Det_Stoch_hsd ~ age, data = selects19)
rsq_sd100 <- summary(result)$r.squared
cat('The R2 is: ', rsq_sd100)

```

7. Present in a table the $R^2$ for each value of the standard deviation.
```{r}

table <- data.frame(
  SD = c(1, 0.1, 0.01),
  R2 = c(rsq_sd1, rsq_sd10, rsq_sd100)    # Replace these with the actual R-squared values
)

print(table)

```
8. Graph $R^2$ agains the standard deviation fraction. Fit a linear regression line.
```{r}
ggplot(table, aes(x = SD, y = R2)) +
  geom_point(size = 0) +
  geom_smooth(method = "lm", formula = y ~ x, se = FALSE, color = "green")+
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5)) +
  labs(
    x = "Fraction of standard deviation",
    y = "R2",
    title = "Relation between R2 and standard deviation of residuals"
  ) 
```
9. [Optional] Graph $R^2$ against the standard deviation fraction. Fit a regression line with a polynomial of degree 2. The regression line fits the data better. Is the polynomial regression more informative than the linear regression? Why? What lesson does this graph give you in terms of the importance of understanding the theoretical relations between variables beyond what an empirical approach could suggest? What does it teach you regarding the tension between under- and over-fitting data?

```{r}
ggplot(table, aes(x = SD, y = R2)) +
  geom_point() +
  geom_smooth(method = "lm", formula = y ~ poly(x, 2), se = FALSE, color='green') +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5)) +
  labs(
    x = "Fraction of standard deviation",
    y = "R2",
    title = "Relation between R2 and standard deviation of residuals"
  ) 



```
10. Print the parameters generated in the point 1. Generate the same predictions as in point 1 and 2 but this time multiply the slope's parameter by 5, while keeping the intercept unchanged. Call the resulting predictions `predicted_LeftToRight_AdjSlope` Generate a graph with the regression line for `predicted_LeftToRight_AdjSlope` vs `Age` and compare it with the graph `predicted_LeftToRight` vs `Age` generated in point 1.

Print here
```{r}
result <- lm(LeftToRight ~ age, data = selects19)
# summary(result)
coeffs <- coef(result)
cat('Intercept:',unname(coeffs[1]), '\n\nSlope:', unname(coeffs[2]))
```

Predict with the adjusted slope here.
```{r}
selects19$predicted_LeftToRight_AdjSlope <- unname(coeffs[1])+(unname(coeffs[2])*5)*selects19$age
```

Generate the graph here.
```{r}
#Means for Y and X
mean_LeftRight <- mean(selects19$predicted_LeftToRight_AdjSlope, na.rm = TRUE)
mean_age <- mean(selects19$age, na.rm = TRUE)

# Create a scatter plot
ggplot(selects19, aes(x = age, y = predicted_LeftToRight_AdjSlope)) +
  geom_smooth(method = "lm", formula = y ~ x, se = FALSE, color = "red") +  # Adding the regression line
  geom_hline(yintercept = mean_LeftRight, linetype = "dashed", color = "green") +  # Horizontal line at the mean of y
  geom_vline(xintercept = mean_age, linetype = "dashed", color = "orange") +  # Vertical line at the mean of x
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5)) +
  scale_y_continuous(
    limits = c(0, 15),
    breaks = seq(0, 20, by = 1)) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5), # Center the plot title
    panel.grid.major.y = element_line(color = "grey80", size = 0.5), # Style for major Y grid lines
    panel.grid.minor.y = element_blank() # Remove minor Y grid lines
  ) +
  labs(
    x = "Age (years)",
    y = "Political Preferences (left to right)",
    title = "Scatter plot Age vs. Political Preferences (adj. slope)"
  )
```
11. Add to the deterministic simulation the same stochastic component generated in point 2. Call that variable `predicted_LeftToRight_AdjSlope_Stoch`. Generate the graph `predicted_LeftToRight_AdjSlope_Stoch` vs `age` with a linear regression line. Generate the $R^2$ and compare it to the one generated in point 4. Why is the new $R^2$ higher than the one in point 4?

Report the simulation and the graph here.
```{r}
selects19$predicted_LeftToRight_AdjSlope_Stoch <- selects19$predicted_LeftToRight_AdjSlope + selects19$NormResiduals1

#Means for Y and X
mean_LeftRight <- mean(selects19$predicted_LeftToRight_AdjSlope_Stoch, na.rm = TRUE)
mean_age <- mean(selects19$age, na.rm = TRUE)

# Create a scatter plot
ggplot(selects19, aes(x = age, y = predicted_LeftToRight_AdjSlope_Stoch)) +
  geom_point(size = 0) +
  geom_smooth(method = "lm", formula = y ~ x, se = FALSE, color = "red") +  # Adding the regression line
  geom_hline(yintercept = mean_LeftRight, linetype = "dashed", color = "green") +  # Horizontal line at the mean of y
  geom_vline(xintercept = mean_age, linetype = "dashed", color = "orange") +  # Vertical line at the mean of x
  scale_y_continuous(
    limits = c(0, 20),
    breaks = seq(0, 20, by = 1)) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5), # Center the plot title
    panel.grid.major.y = element_line(color = "grey80", size = 0.5), # Style for major Y grid lines
    panel.grid.minor.y = element_blank() # Remove minor Y grid lines
  ) +
  labs(
    x = "Age (years)",
    y = "Simulation: Political Preferences (left to right)",
    title = "Scatter plot Age vs. Political Preferences \n(determ.& stoch. sim. with adjusted slope)"
  )
```

Report the new $R^2$ here:
```{r}
result <- lm(predicted_LeftToRight_AdjSlope_Stoch ~ age, data = selects19)
rsq_sd1_AdjSlope <- summary(result)$r.squared
cat('The R2 is: ', rsq_sd1_AdjSlope)

```

Report why is the new $R^2$ higher than the one in point 4?

```{r}
print('The reason the R2 increased is that, while the distance from each observation to the regression line remained unchainged (i.e., the residual was kept unchanged), by increasing the slope of the generating process, the average distance between each observation and the average observation increased (i.e., Y\'s variance increased). See the graph with the red and blue squares mentioned in point 5.')
```

333333333333


12. Print the parameters generated in the point 1. Generate the same predictions as in point 1 and 2 but this time increase in two units the *intercept's* parameter (not the *slope's* parameter as in the point 10), while keeping the slope unchanged. Call the resulting predictions `predicted_LeftToRight_AdjSlope` Generate a graph with the regression line for `predicted_LeftToRight_AdjSlope` vs `Age` and compare it with the graph `predicted_LeftToRight` vs `Age` generated in point 1.

Print here
```{r}
result <- lm(predicted_LeftToRight_AdjSlope_Stoch ~ age, data = selects19)
# summary(result)
coeffs12 <- coef(result)
cat('Intercept:',unname(coeffs12[1]), '\n\nSlope:', unname(coeffs12[2]))
```

Predict with the adjusted slope here.
```{r}
selects19$predicted_LeftToRight_AdjIntecept <- unname(coeffs[1]+2)+(unname(coeffs[2]))*selects19$age
```

Generate the graph here.
```{r}
#Means for Y and X
mean_LeftRight <- mean(selects19$predicted_LeftToRight_AdjIntecept, na.rm = TRUE)
mean_age <- mean(selects19$age, na.rm = TRUE)

# Create a scatter plot
ggplot(selects19, aes(x = age, y = predicted_LeftToRight_AdjIntecept)) +
  geom_smooth(method = "lm", formula = y ~ x, se = FALSE, color = "red") +  # Adding the regression line
  geom_hline(yintercept = mean_LeftRight, linetype = "dashed", color = "green") +  # Horizontal line at the mean of y
  geom_vline(xintercept = mean_age, linetype = "dashed", color = "orange") +  # Vertical line at the mean of x
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5)) +
  scale_y_continuous(
    limits = c(0, 15),
    breaks = seq(0, 20, by = 1)) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5), # Center the plot title
    panel.grid.major.y = element_line(color = "grey80", size = 0.5), # Style for major Y grid lines
    panel.grid.minor.y = element_blank() # Remove minor Y grid lines
  ) +
  labs(
    x = "Age (years)",
    y = "Political Preferences (left to right)",
    title = "Scatter plot Age vs. Political Preferences (adj. slope)"
  )
```
13. Add to the deterministic simulation the same stochastic component generated in point 2. Call that variable `predicted_LeftToRight_AdjIntercep_Stoch`. Generate the graph `predicted_LeftToRight_AdjIntecept` vs `age` with a linear regression line. Generate the $R^2$ and compare it to the one generated in point 4. Why is the new $R^2$ higher than the one in point 4?

Report the simulation and the graph here.
```{r}
selects19$predicted_LeftToRight_AdjIntercept_Stoch <- selects19$predicted_LeftToRight_AdjIntecept + selects19$residual

#Means for Y and X
mean_LeftRight <- mean(selects19$predicted_LeftToRight_AdjIntercept_Stoch, na.rm = TRUE)
mean_age <- mean(selects19$age, na.rm = TRUE)

# Create a scatter plot
ggplot(selects19, aes(x = age, y = predicted_LeftToRight_AdjIntercept_Stoch)) +
  geom_point(size = 0) +
  geom_smooth(method = "lm", formula = y ~ x, se = FALSE, color = "red") +  # Adding the regression line
  geom_hline(yintercept = mean_LeftRight, linetype = "dashed", color = "green") +  # Horizontal line at the mean of y
  geom_vline(xintercept = mean_age, linetype = "dashed", color = "orange") +  # Vertical line at the mean of x
  scale_y_continuous(
    limits = c(0, 20),
    breaks = seq(0, 20, by = 1)) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5), # Center the plot title
    panel.grid.major.y = element_line(color = "grey80", size = 0.5), # Style for major Y grid lines
    panel.grid.minor.y = element_blank() # Remove minor Y grid lines
  ) +
  labs(
    x = "Age (years)",
    y = "Simulation: Political Preferences (left to right)",
    title = "Scatter plot Age vs. Political Preferences \n(determ.& stoch. sim. with adjusted intercept)"
  )
```
Regress the `predicted_LeftToRight_AdjIntercept_Stoch` on `age`
```{r}
result <- lm(predicted_LeftToRight_AdjIntercept_Stoch ~ age, data = selects19)
rsq_sd1_AdjIntercept <- summary(result)$r.squared
coeffs13 <- coef(result)
cat('Intercept:',unname(coeffs13[1]), '\n\nSlope:', unname(coeffs13[2]))
```

Report the $R^2$ generated in points 2, 11, and 13 here:
```{r}
tableSD1 <- data.frame(
  LookR2 = c('Point 2', 'Point 12', 'Point 13'),
  Model = c('Unchanged', 'P2 + (slope*5)', 'P2+(intercept+2)'),
  R2 = c(rsq_sd1, rsq_sd1_AdjSlope, rsq_sd1_AdjIntercept),    
  LookParams = c('Point 1', 'Point 12', 'Point 13'),
  Intercept = c(unname(coeffs1[1]), unname(coeffs12[1]), unname(coeffs13[1])),    
  Slope = c(unname(coeffs1[2]), unname(coeffs12[2]), unname(coeffs13[2]))
)


print(tableSD1)

```

14. Comparing the $R^2$ and the parameters across the models of points 1, 2, and 3 answer the following questions:

  i. What effect does increasing the slope of the data generating process (while keeping the residuals and intercept unchanged) have on the $R^2$?
```{r}
print('The R2 increases as seen in point 11')
```

  ii. What effect does increasing the intercept of the data generating process (while keeping the residuals and slope unchanged) have on the $R^2$?
```{r}
print('The R2 stays unchanged as the distance from each observation to the regression line remained unchainged (i.e., the residual was kept unchanged) as well as the average distance between each observation and the average observation remained unchainged (i.e., Y\'s variance was kept unchanged)')

```
 
 iii. What effect does increasing the slope of the data generating process (while keeping the residuals and intercept unchanged) have on the intercept and slope?
```{r}
print('It increases the estimated slope and decreases the intercept.')
```
 
 iv. What effect does increasing the intercept of the data generating process (while keeping the residuals and slope unchanged) have on the intercept and slope?
```{r}
print('It keeps the estimated slope unchanged and the estimated intercept is the same as before the adjustment but increases by the same value that the whole data generating process was modified.')

```

```{r}
```

```{r}
```

```{r}
```

```{r}
```

```{r}
```