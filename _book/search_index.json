[["index.html", "Intermediate Quantitative Methods About 0.1 How to use these exercises? 0.2 Schedule", " Intermediate Quantitative Methods Lucas Lemmann 2023-11-22 About What is this book about? What for? 0.1 How to use these exercises? Besides the 14 lectures, the course will be organized around 12 non-graded exercises: 5 labs 7 do-it-yourself (DIYS) The labs’ solutions will be discussed in detail between TAs and students in the corresponding sessions, while DIYS will not. In both cases, we will publish the solutions the week after the exercise is due. We encourage you to prepare for the lab sessions in advance as well as to attend them to discuss any doubts they might have related to the labs material. To prevent redundant communications (i.e., emails with the same information), share your questions regarding the exercises in the forum. Labs will emphasize the most voted questions. While we encourage and foster a collaborative learning process, we expect you to work individually first. I.e., try to address the task on your own first, identify what is limiting you, try to solve it on your own (not for too long), and, if you cannot find a solution, reach out your classmates. Once you find your solution, consider discussing the solution with your classmates. 0.2 Schedule Week Dates Exercise type 1 19-25/02 DIYS 1 2 26/02-03/03 Lab 1 3 04/03-10/03 Lab 1 4 11/03-17/03 DIYS 2 5 18/03-24/03 Lab 2 6 25/03-31/03 DIYS 3 Spring Break 28/03-07/04 None? 7 08/04-14/04 Lab 3 8 15/04-21/04 DIYS 4 9 22/04-28/04 Lab 4 10 29/04-05/05 DIYS 5 11 06/05-12/05 Lab 5 12 13/05-19/05 Lab 5 13 20/05-26/05 DIYS 6 14 27/05-02/06 DIYS 7 "],["week-1-diys-1.html", "Chapter 1 Week 1: DIYS 1 1.1 Aims: 1.2 First Part: Descriptive Analysis 1.3 Second Part: Exploratory VS. Hypothesis-Testing Analysis 1.4 Graph 1.5 Solution", " Chapter 1 Week 1: DIYS 1 1.1 Aims: To refresh your R skills. Performing some basic analyses (i.e., descriptive, exploratory, and hypothesis testing ones). 1.2 First Part: Descriptive Analysis Download the files f.txt and m.txt. They contain information on the number of steps in a day and the body mass index (BMI) for female and male individuals respectively. Open them and explore the first 5 observations for each file. Adjust using the links from GitHub # Your code goes here For the exercise before publishing the solution # open data female &lt;- read.table(&quot;~/Documents/0_IPZ/2023_2/Leemann-QuantMethods/QuantitativeMethods/QuantitativeMethods/Data/f.txt&quot;, header = TRUE, sep = &quot;\\t&quot;) # explore data head(female, 3) ## ID steps bmi ## 1 3 15000 17.0 ## 2 4 14861 17.2 ## 3 5 14861 17.2 # open data male &lt;- read.table(&quot;~/Documents/0_IPZ/2023_2/Leemann-QuantMethods/QuantitativeMethods/QuantitativeMethods/Data/m.txt&quot;, header = TRUE, sep = &quot;\\t&quot;) # explore data head(male, 3) ## ID steps bmi ## 1 1 15000 16.9 ## 2 2 15000 16.9 ## 3 6 14861 16.8 Some key functions in dplyr can be categorized as dealing with columns (e.g., select, mutate), rows (e.g., filter, distinct, arrange), or groups (e.g., group_by, summarise, and count). Let’s use some of them! Select only the columns ‘steps’ and ‘bmi’. Do it only for the first three observations of the data on females. # It&#39;s necessary to restate it in each r code section so the book can be rendered. library(dplyr) head(female, 3) %&gt;% select(steps, bmi) ## steps bmi ## 1 15000 17.0 ## 2 14861 17.2 ## 3 14861 17.2 Select all columns except ‘ID’. Do not use steps nor bmi. Do it only for the first three observations of the data on females. Is the resulting table the same as the previous point? If not, check your answer. library(dplyr) head(female, 3) %&gt;% select(-ID) ## steps bmi ## 1 15000 17.0 ## 2 14861 17.2 ## 3 14861 17.2 Note: to check the documentation of select, use ?select on the console. Use mutate to create a new column in the dataframe female called StepsTimesBmi formed as the product of steps and bmi. Show the first three observations for the new variable. library(dplyr) female &lt;-female %&gt;% mutate(StepsTimesBmi= steps * bmi) head(female$StepsTimesBmi,3) ## [1] 255000.0 255609.2 255609.2 Get rid of the column StepsTimesBmi. Use subset. female &lt;- subset(female, select= - StepsTimesBmi) Use filter to find the share of female individuals with a bmi higher than 20 and lower than 21. library(dplyr) f20_21 &lt;- female %&gt;% filter(bmi&gt;20, bmi&lt;21) cat(&quot;The share of female individuals with a `bmi` higher than 20 and lower than 21 is:&quot;, nrow(f20_21)*100/nrow(female), &quot;%\\n&quot;) ## The share of female individuals with a `bmi` higher than 20 and lower than 21 is: 2.28013 % Use filter to find the share of female individuals with a bmi higher than 20 and lower than 21 while at the same time having less than 14000 steps. library(dplyr) fBMI20_21_Step14000 &lt;- female %&gt;% filter(bmi&gt;20, bmi&lt;21, steps&lt;14000) cat(&quot;The share of female individuals with a `bmi` higher than 20 and lower than 21 while at the same time having less than 14000 is:&quot;, nrow(fBMI20_21_Step14000)*100/nrow(female), &quot;%\\n&quot;) ## The share of female individuals with a `bmi` higher than 20 and lower than 21 while at the same time having less than 14000 is: 1.737242 % Use filter to find the share of male individuals with ID number lower than 5 and higher than 860. Notice that you can use either &amp; between conditions or simply a comma. Could any data set generate a different answer? Why? library(dplyr) m_5_860 &lt;- male %&gt;% filter(ID&lt;5 &amp; ID&gt;860) cat(&quot;The share of male individuals with `ID` number lower than 5 AND higher than 860 is:&quot;, nrow(m_5_860)*100/nrow(male), &quot;%\\n&quot;) ## The share of male individuals with `ID` number lower than 5 AND higher than 860 is: 0 % Use filter to find the share of male individuals with ID number lower than 5 or higher than 860. Use | between conditions. Could any data set generate a different answer? Why? library(dplyr) m_5_or_860 &lt;- male %&gt;% filter(ID&lt;5 | ID&gt;860) cat(&quot;The share of male individuals with `ID` number lower than 5 OR higher than 860 is:&quot;, nrow(m_5_or_860)*100/nrow(male), &quot;%\\n&quot;) ## The share of male individuals with `ID` number lower than 5 OR higher than 860 is: 46.35838 % Use distinct to identify the share of male IDs that are unique. unique_m_IDs &lt;- male %&gt;% distinct(ID) cat(&quot;The share of male IDs that are unique is:&quot;, nrow(unique_m_IDs)*100/nrow(male), &quot;%\\n&quot;) ## The share of male IDs that are unique is: 100 % Use arrange to find the three highest and lowest BMI values for males. Use slice_head. # Max top_3_m &lt;- male %&gt;% arrange(desc(bmi)) %&gt;% slice_head(n = 3) print(top_3_m) ## ID steps bmi ## 1 786 7894 32 ## 2 847 7593 32 ## 3 863 7431 32 # Min bottom_3_m &lt;- male %&gt;% arrange(bmi) %&gt;% slice_head(n = 3) print(bottom_3_m) ## ID steps bmi ## 1 1170 6366 15.7 ## 2 614 9097 15.8 ## 3 615 9097 15.8 9. group_by summarise count Are there repeated ids within each data set? # get package # install.packages(&quot;dplyr&quot;) library(dplyr) # Check for repeated IDs in the female data set. How many are there? repeated_ids_female &lt;- female %&gt;% group_by(ID) %&gt;% filter(n() &gt; 1) cat(&quot;Number of repeated IDs in the female data set:&quot;, nrow(repeated_ids_female), &quot;\\n&quot;) ## Number of repeated IDs in the female data set: 0 # Check for repeated IDs in the male data set. How many are there? repeated_ids_male &lt;- male %&gt;% group_by(ID) %&gt;% filter(n() &gt; 1) cat(&quot;Number of repeated IDs in the male data set:&quot;, nrow(repeated_ids_male), &quot;\\n&quot;) ## Number of repeated IDs in the male data set: 0 1.3 Second Part: Exploratory VS. Hypothesis-Testing Analysis Please read the whole instruction before solving the exercise. Each student will be randomly allocated to either doing the task 1 or 2 (a list containing those numbers will published). Both tasks are based on the same data sets used in the first part. Notes: The details of the data origin will be published with the solution. Students allocated to each group are encouraged to do the task for the other group only after finishing their own task. 1.3.1 Preliminary steps: do this before doing the task that you were assigned to For each data set, create a new variable called sex. Assign any value to each case, but make sure they are different. female$sex &lt;- &#39;F&#39; male$sex &lt;- &#39;M&#39; Create one data frame with all the IDs present in both data sets. How many cases are there? Use dplyr’s join methods. library(dplyr) in_both &lt;- inner_join(female, male, by=&quot;ID&quot;) cat(&quot;The number of cases where an ID is in both data sets is:&quot;, nrow(in_both), &quot;\\n&quot;) ## The number of cases where an ID is in both data sets is: 0 Now that you know that there are no repeated individuals across the data sets, consider whether a join method is the appropriate way of unifying both data sets. Try first with full_join and then with bind_rows. Which one should you use? Why? Finally, how many individuals does the new dataframe have? library(dplyr) all &lt;- full_join(female, male, by=&quot;ID&quot;, copy=FALSE) cat(&quot;The new dataframe has &quot;, nrow(all), &quot;individuals\\n&quot;) ## The new dataframe has 1786 individuals # Assuming that `sex` was created for each dataframe all &lt;- bind_rows(female, male, .id = NULL) cat(&quot;The new dataframe has &quot;, nrow(all), &quot;individuals\\n&quot;) ## The new dataframe has 1786 individuals # Without assuming that `sex` was created for each dataframe female &lt;- read.table(&quot;~/Documents/0_IPZ/2023_2/Leemann-QuantMethods/QuantitativeMethods/QuantitativeMethods/Data/f.txt&quot;, header = TRUE, sep = &quot;\\t&quot;) male &lt;- read.table(&quot;~/Documents/0_IPZ/2023_2/Leemann-QuantMethods/QuantitativeMethods/QuantitativeMethods/Data/m.txt&quot;, header = TRUE, sep = &quot;\\t&quot;) all &lt;- bind_rows(female, male, .id = &#39;sex&#39;) cat(&quot;The new dataframe has &quot;, nrow(all), &quot;individuals\\n&quot;) ## The new dataframe has 1786 individuals # Which assigns a number 1 for the first binded dataframe, and 2 for the second one. Hence, we can replace the values as follows. all$sex &lt;- ifelse(all$sex == 1, &#39;F&#39;, ifelse(all$sex == 2, &#39;M&#39;, all$sex)) What’s the share per sex in the unified dataframe from the previous point? Use `` Consider using the packages dplyr, `` 1.3.2 Task 1: What do you conclude from the combined data set (i.e., the one formed using both the one for males and the one for females)? What questions did you ask yourself? Why did you ask those questions? Is there an intuition behind them? If so, what was your intuition? If not, how did you proceed? Hint: consider visualizing how variables interact. 1.3.3 Task 2: Is the average number of steps for males and females statistically different? How do BMI and daily steps statistically relate to each other? Does that relationship depend on whether individuals are of one sex or another? If so, how? Is there an statistically significant negative correlation between the number of steps and the BMI for females? Is there an statistically significant positive correlation between the number of steps and the BMI for males? 1st weeks, dplier: to check&gt; to statistical analysis Doing basic code to make analysis (which is fine enough), but in dplier you could do it like this. Make descriptive statistics using an interesting looking for something unknown in the dark, grope, feel blindly and make conjectures on what things are and how they are related. - Two groups: random selection: description similar? The smaller the group, the likelier that a random selection is not balanced? What about attrition? Looking!=seeing: Different beliefs (non- and knowledge ones), different preferences, different attention focus -&gt; different attention investment and emphasis Value of diverse academic community while keeping a minimal set of shared assessment rules: objectivity as continuum of increasing inter-subjective agreement 1.4 Graph #install.packages(&quot;ggplot2&quot;) library(ggplot2) ggplot(female, aes(x = steps, y = bmi)) + geom_point() + labs(x = &quot;Steps&quot;, y = &quot;BMI&quot;) + ggtitle(&quot;Scatterplot of Steps vs BMI by Sex&quot;) ggplot(male, aes(x = steps, y = bmi)) + geom_point() + labs(x = &quot;Steps&quot;, y = &quot;BMI&quot;) + ggtitle(&quot;Scatterplot of Steps vs BMI by Sex&quot;) ggplot(all, aes(x = steps, y = bmi, color = sex)) + geom_point() + labs(x = &quot;Steps&quot;, y = &quot;BMI&quot;) + ggtitle(&quot;Scatterplot of Steps vs BMI by Sex&quot;) + scale_color_manual(values = c(&quot;F&quot; = &quot;blue&quot;, &quot;M&quot; = &quot;red&quot;)) # Optional: Define color mapping 1.5 Solution Will be made available. "],["week-2.html", "Chapter 2 Week 2 2.1 Exercise 2.2 Solution", " Chapter 2 Week 2 2.1 Exercise 2nd: simulated dataset and increase the variance: how does that affects the standard error 2.2 Solution Data taken from here. Original selective attention, here. Suicide awareness campaign, here. "],["week-3-regression-i-prediction.html", "Chapter 3 Week 3: Regression I (Prediction) 3.1 Aims 3.2 Exercise: Context and Question 3.3 Getting the data first 3.4 Exercise: solution", " Chapter 3 Week 3: Regression I (Prediction) 3.1 Aims Using regression analysis for quantitative descriptive purposes with real data Using simulation to instantiate how different properties of the data generating process alter the reliability of regression analysis 3.2 Exercise: Context and Question As developed in the following entry, a referendum took place in 2021 to assess whether Swiss citizens approved or not a bill aimed at reducing greenhouse gas emissions. The bill was rejected by a narrow margin: 51.6% of votes went for the “No”, while 48.4% for the “Yes”. In the media, some analysts commented that a marked division or cleavage between rural and urban voters seems to have led to this result: a specially high rural turn-out seems to underlie such result. As the analyst commented, most urban inhabitants liked the bill while most rural inhabitants disliked it. Not satisfied with a simple impression, as a political scientist you want to quantitatively qualify your understanding about what happened in that election. Particularly, you want to know: Given that more rural municipalities have smaller populations, was the turn-out higher in municipalities with smaller populations than in bigger ones? Was the turn-out higher in more agricultural municipalities than in less agricultural ones? Thus, to analytically describe the voting results, you will perform some regressions using the following data. 3.3 Getting the data first To get the data, you will use an API (application programming interface). Put plainly, for the sake of this exercise you can think of an API like a waiter to whom you make a request and who gets what ever you requested from the kitchen (a remote data source). In this case, you will use two APIs: to get election results in Switzerland, swissdd, and BFS to get many other kinds of statistical information. Both APIs get information from the Federal Statistical Office (Bundesamt für Statistik). Skimm the functions of the Swissdd package. Then, inspect the codebook to understand what for the columns and rows stand for. Do not use more than 5 minutes doing it. To get the data, simply execute the following code. We present you with the code so, if you want, you can know how it works and you can play around with it on your own following the code’s logic. Install the Swissdd package #First option - from CRAN. If you install it from the github repository, make sure you have the `devtools` installed in advance. #install.packages(&quot;swissdd&quot;) #Second option # install.packages(&quot;devtools&quot;) # it is necessary to comment the install.packages so the book can be rendered devtools::install_github(&quot;politanch/swissdd&quot;) # library(swissdd) Retrieve the CO2 Act information using get_nationalvotes. The vote took place in 13/06/2021. CO2&lt;-get_nationalvotes(votedates = &quot;2021-06-13&quot;) As the same day of the CO2 Act vote more initiatives were voted, keep only the one we care about for this exercise. Notice that each initiative has a numerical identifier called id. Here you can find the numerical identifier under Vote Nº. Keep in mind that, the variable id has the same number as in Vote Nº with an additional zero to the right. CO2&lt;- CO2 %&gt;% filter(id==6440) The resulting data frame contains rows representing the results for a particular vote in a particular municipality. The columns qualify that vote. Use the colnames() function to see the names of the columns. Keep only those that might be relevant for your analysis. CO2&lt;- CO2 %&gt;% select(canton_id, canton_name, mun_id, mun_name, jaStimmenInProzent, jaStimmenAbsolut, neinStimmenAbsolut, stimmbeteiligungInProzent, eingelegteStimmzettel, anzahlStimmberechtigte, gueltigeStimmen) Finally, as you want to see the turn-out differences between municipalities with different degrees of agriculture intensity you need to get some additional data. Run the following code. # install.packages(&quot;BFS&quot;) # library(BFS) #To see the information available in German # catalog_data_de &lt;- bfs_get_catalog_data(language = &quot;de&quot;) #To see the information available in English #catalog_data_en &lt;- bfs_get_catalog_data(language = &quot;en&quot;) #To see the information available in German that contains a particular word in the title #catalog_data_de &lt;- bfs_get_catalog_data(language = &quot;de&quot;, title=&quot;Gemeinde&quot;) #To get the asset number (i.e., numerical id for a data set) # asset_number &lt;- catalog_data_de %&gt;% # filter(title == &quot;Arealstatistik: Standardnomenklatur (NOAS04) nach Bezirk und Gemeinde, in Hektaren&quot;) %&gt;% # pull(number_asset) #Using that asset number, the metadata (i.e., data that describes the data set) can be accessed. #asset_meta &lt;- bfs_get_asset_metadata(number_asset = asset_number) #From the metadata, the bfs number (i.e., a alphanumeric id for the data set) can be accessed. #bfs_number &lt;- asset_meta$shop$orderNr #Finally, using the bfs number the data set can be accessed. #LandUse &lt;- bfs_get_data(number_bfs = bfs_number) #If there is a “Too Many Requests” error message, you can follow this (https://github.com/lgnbhl/BFS#too-many-requests-error-message) #or download the PX file from here https://www.bfs.admin.ch/bfs/de/home/statistiken/kataloge-datenbanken/daten.assetdetail.24865343.html #install.packages(&quot;pxR&quot;) # library(pxR) #Open data LandUse &lt;- read.px(&#39;~/Documents/0_IPZ/2023_2/Leemann-QuantMethods/QuantitativeMethods/QuantitativeMethods/Data/px-x-0202020000_102.px&#39;, encoding = &quot;UTF-8&quot;) LandUseData&lt;- LandUse$DATA$value #Rename variable LandUseData &lt;- LandUseData %&gt;% rename_with(~ &#39;mun_name&#39;, 3) #Keep the data relevant for my analysis LandUseData&lt;- LandUseData %&gt;% filter(Periode == &quot;2013/18&quot;) %&gt;% filter(Standardnomenklatur..NOAS04.==&quot;-b Landwirtschaftsflächen&quot; | Standardnomenklatur..NOAS04.==&quot;Fläche Total&quot;) %&gt;% filter(str_starts(str_trim(mun_name), fixed(&quot;.&quot;))) %&gt;% mutate(mun_name = str_replace_all(mun_name, fixed(&quot;......&quot;), &quot;&quot;)) # install.packages(&quot;tidyverse&quot;) #Adjust data from long to wide LandUseData &lt;- LandUseData %&gt;% pivot_wider(names_from = Standardnomenklatur..NOAS04., values_from = value) #Rename variables LandUseData &lt;- LandUseData %&gt;% rename_with(~ &#39;TotalAreaHa&#39;, 3) %&gt;% rename_with(~ &#39;AgriculturalAreaHa&#39;, 4) %&gt;% select(-Periode) Using the additional data, you can now merge both data sets so you can know how did voters behave in more agricultural areas. Use the inner_join function. The numerical IDs are available in LandUseData but not in CO2. However, as both sources share the mun_name, you use that variable to match them. CO2 &lt;- inner_join(CO2, LandUseData, by=&quot;mun_name&quot;) 3.4 Exercise: solution Note: Remember that you can copy the code from one point to answer another point. Simply make the necessary adjustments. 3.4.1 Real data Using the previous data, you do the following to answer your two questions: Since you want to describe the turn-out across municipalities with different population sizes, you initially think of regressing the turn-out on the population size. As you lack the municipal population, you use the number of eligible voters anzahlStimmberechtigte as a proxy. Regress stimmbeteiligungInProzent (Voting participation in percent) on anzahlStimmberechtigte (number of eligible voters) without the intercept. Report and interpret the parameter. Write the regression here. result &lt;- lm(stimmbeteiligungInProzent ~ anzahlStimmberechtigte -1 , data = CO2) summary(result) ## ## Call: ## lm(formula = stimmbeteiligungInProzent ~ anzahlStimmberechtigte - ## 1, data = CO2) ## ## Residuals: ## Min 1Q Median 3Q Max ## -556.58 52.77 61.07 68.11 96.02 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## anzahlStimmberechtigte 0.0026344 0.0001777 14.82 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 62.41 on 2131 degrees of freedom ## Multiple R-squared: 0.09349, Adjusted R-squared: 0.09307 ## F-statistic: 219.8 on 1 and 2131 DF, p-value: &lt; 2.2e-16 Report and interpret the parameter here. coeffs&lt;- coef(result) cat(&#39;The beta value for&#39;, names(coeffs[1]), &#39; is &#39;, round(unname(coeffs[1]), digits = 5), &#39;. It means that, across Swiss municipalities an increase of a thousand voters was associated with an average increase in the turn-out of &#39;, round(unname(coeffs[1])*1000, digits = 5), &#39; percentage points.&#39;) ## The beta value for anzahlStimmberechtigte is 0.00263 . It means that, across Swiss municipalities an increase of a thousand voters was associated with an average increase in the turn-out of 2.63439 percentage points. [Optional] Why could the number of eligible voters inform better your inquiry than the total municipal population? What difference across municipalities could make an analysis based on municipal population render the analysis less reliable? To enrich your analysis, you generate a scatter plot showing the relation between the same pair of variables and qualifying it adding the regression line. Remember that you are doing the analysis without the intercept. # Create a scatter plot ggplot(CO2, aes(x = anzahlStimmberechtigte, y = stimmbeteiligungInProzent)) + geom_point() + geom_smooth(method = &quot;lm&quot;, formula = y ~ x - 1, se = FALSE, color = &quot;purple&quot;) + # Adding the regression line scale_y_continuous(limits = c(0, max(CO2$stimmbeteiligungInProzent, na.rm = TRUE))) + theme_minimal() + labs( x = &quot;Number of eligible voters&quot;, y = &quot;Voting Participation (%)&quot;, title = &quot;Scatter plot with Linear Regression Line&quot; ) Given your preliminary analysis, you find that, on average, municipalities with bigger populations had a higher turn-out than those with smaller ones. As you know that most urban citizens preferred ‘Yes’ but the ‘No’ won, you call into question your first approach: while bigger municipalities had higher participation levels than smaller ones, the option preferred by most rural inhabitants won. In other words, it is not clear that the population size helps us to understand this voting results. Thus, to capture how rural a municipality is, you used the agricultural area of the municipality (AgriculturalAreaHa) as a regressor (aka. independent variable) for the same regressand (aka. dependent variable) of the previous point (i.e., voting participation in percent). Again, do the regression without intercept. Report and interpret the parameter. Also present the corresponding graph. Write the regression here. result &lt;- lm(stimmbeteiligungInProzent ~ AgriculturalAreaHa -1 , data = CO2) summary(result) ## ## Call: ## lm(formula = stimmbeteiligungInProzent ~ AgriculturalAreaHa - ## 1, data = CO2) ## ## Residuals: ## Min 1Q Median 3Q Max ## -357.41 40.38 51.27 58.59 87.83 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## AgriculturalAreaHa 0.0312861 0.0009688 32.29 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 53.71 on 2131 degrees of freedom ## Multiple R-squared: 0.3286, Adjusted R-squared: 0.3283 ## F-statistic: 1043 on 1 and 2131 DF, p-value: &lt; 2.2e-16 Report and interpret the parameter here. coeffs&lt;- coef(result) cat(&#39;The beta value for&#39;, names(coeffs[1]), &#39; is &#39;, round(unname(coeffs[1]), digits = 5), &#39;. It means that, across Swiss municipalities an increase of a thousand hectares was associated with an average increase in the turn-out of &#39;, round(unname(coeffs[1])*1000, digits = 5), &#39; percentage points.&#39;) ## The beta value for AgriculturalAreaHa is 0.03129 . It means that, across Swiss municipalities an increase of a thousand hectares was associated with an average increase in the turn-out of 31.28612 percentage points. Present the graph here. # Create a scatter plot ggplot(CO2, aes(x = AgriculturalAreaHa, y = stimmbeteiligungInProzent)) + geom_point() + geom_smooth(method = &quot;lm&quot;, formula = y ~ x - 1, se = FALSE, color = &quot;purple&quot;) + # Adding the regression line scale_y_continuous(limits = c(0, max(CO2$stimmbeteiligungInProzent, na.rm = TRUE))) + # theme_minimal() + labs( x = &quot;Agricultural Area (Ha)&quot;, y = &quot;Voting Participation (%)&quot;, title = &quot;Scatter plot with Linear Regression Line&quot; ) The result from the previous point is consistent with the vote result given the urban-rural divide in preferences (i.e., municipalities with more agricultural area had higher participation rates). However, you notice that your comparisons across municipalities are not very rigorous because you are ignoring how important agricultural land with respect to the whole municipality area. An implication of that is that two municipalities with the same agricultural area could be taken as equally rural while one could have a very big urban area (e.g., Zurich) and the other have a very small one. Thus to make your analysis across more comparable units, you transform the absolute value of the agricultural area to a relative one: the percentage of the municipal area that is agricultural. Create the variable AgricAreaPercent to represent those transformed values. Regress the turn-out on the newly created variable. Again, do the regression without intercept. Report and interpret the parameter. Also present the corresponding graph. Write the regression here. #Transform the units to make them comparable CO2 &lt;- CO2 %&gt;% mutate(AgricAreaPercent= 100*AgriculturalAreaHa/TotalAreaHa) #regression result0 &lt;- lm(stimmbeteiligungInProzent ~ AgricAreaPercent -1 , data = CO2) summary(result0) ## ## Call: ## lm(formula = stimmbeteiligungInProzent ~ AgricAreaPercent - 1, ## data = CO2) ## ## Residuals: ## Min 1Q Median 3Q Max ## -42.102 -7.509 6.449 23.631 83.331 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## AgricAreaPercent 1.26144 0.01012 124.7 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 22.75 on 2131 degrees of freedom ## Multiple R-squared: 0.8795, Adjusted R-squared: 0.8794 ## F-statistic: 1.555e+04 on 1 and 2131 DF, p-value: &lt; 2.2e-16 Report and interpret the parameter here. coeffs&lt;- coef(result0) cat(&#39;The beta value for&#39;, names(coeffs[1]), &#39; is &#39;, round(unname(coeffs[1]), digits = 2), &#39;. It means that, across Swiss municipalities an increase of one percentage point in the share of agricultural land was associated with an average increase in the turn-out of &#39;, round(unname(coeffs[1]), digits = 2), &#39; percentage points.&#39;) ## The beta value for AgricAreaPercent is 1.26 . It means that, across Swiss municipalities an increase of one percentage point in the share of agricultural land was associated with an average increase in the turn-out of 1.26 percentage points. Present the graph here. # Create a scatter plot ggplot(CO2, aes(x = AgricAreaPercent, y = stimmbeteiligungInProzent)) + geom_point() + geom_smooth(method = &quot;lm&quot;, formula = y ~ x - 1, se = FALSE, color = &quot;purple&quot;) + # Adding the regression line scale_y_continuous(limits = c(0, max(CO2$stimmbeteiligungInProzent, na.rm = TRUE))) + # theme_minimal() + labs( x = &quot;Agricultural Area (%)&quot;, y = &quot;Voting Participation (%)&quot;, title = &quot;Scatter plot with Linear Regression Line&quot; ) The previous graph showed you the same relationship consistent with the vote. However, you now notice that the regression line is strange: if it is supposed to be the line described the general tendency in the relation between two variables, it is strange that it is very far from many observations and only close to few of them. Hence, you remember that the using the intercept increases the fit of the line. Accordingly, you do all the same steps of the previous point but this time with the intercept. Write the regression here. #regression result1 &lt;- lm(stimmbeteiligungInProzent ~ AgricAreaPercent, data = CO2) summary(result1) ## ## Call: ## lm(formula = stimmbeteiligungInProzent ~ AgricAreaPercent, data = CO2) ## ## Residuals: ## Min 1Q Median 3Q Max ## -19.971 -4.760 -0.270 4.314 39.145 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 55.189867 0.384603 143.5 &lt;2e-16 *** ## AgricAreaPercent 0.219491 0.007894 27.8 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 6.969 on 2130 degrees of freedom ## Multiple R-squared: 0.2663, Adjusted R-squared: 0.2659 ## F-statistic: 773.1 on 1 and 2130 DF, p-value: &lt; 2.2e-16 Report and interpret the parameter here. coeffs&lt;- coef(result1) cat(&#39;The beta value for&#39;, names(coeffs[2]), &#39; is &#39;, round(unname(coeffs[2]), digits = 2), &#39;. It means that, across Swiss municipalities an increase of one percentage point in the share of agricultural land was associated with an average increase in the turn-out of &#39;, round(unname(coeffs[2]), digits = 2), &#39; percentage points.\\n\\nLikewise, should there be a municipality with no agricultural area, we could expect it to have a turn-out of &#39;, round(unname(coeffs[1]), digits = 2), &#39;. From there on, increasing one percentage point at a time up to 100 percentage points (i.e., a municipality with 100% of agricultural area), we would have a turn-out of &#39;, round(unname(coeffs[1]), digits = 2)+round(unname(coeffs[2]*100), digits = 2)) ## The beta value for AgricAreaPercent is 0.22 . It means that, across Swiss municipalities an increase of one percentage point in the share of agricultural land was associated with an average increase in the turn-out of 0.22 percentage points. ## ## Likewise, should there be a municipality with no agricultural area, we could expect it to have a turn-out of 55.19 . From there on, increasing one percentage point at a time up to 100 percentage points (i.e., a municipality with 100% of agricultural area), we would have a turn-out of 77.14 Present the graph here. # Create a scatter plot ggplot(CO2, aes(x = AgricAreaPercent, y = stimmbeteiligungInProzent)) + geom_point() + geom_smooth(method = &quot;lm&quot;, formula = y ~ x, se = FALSE, color = &quot;purple&quot;) + # Adding the regression line scale_y_continuous(limits = c(25, max(CO2$stimmbeteiligungInProzent, na.rm = TRUE))) + # theme_minimal() + labs( x = &quot;Agricultural Area (%)&quot;, y = &quot;Voting Participation (%)&quot;, title = &quot;Scatter plot with Linear Regression Line&quot; ) [Optional] You noticed that the regression using the intercept fits better the data: on average, the distance from each point to the regression line is lower. See this entry, particularly the graph with the blue and red squares to understand the logic of the R^2 as a measure for goodness of fit. You want to compare both the regression lines with and without the intercept in one same graph. Do it. What lesson can you get from this comparison? ggplot(CO2, aes(x = AgricAreaPercent, y = stimmbeteiligungInProzent)) + geom_point() + geom_smooth(method = &quot;lm&quot;, formula = y ~ x-1, se = FALSE, color = &quot;red&quot;) + # Adding the regression line geom_smooth(method = &quot;lm&quot;, formula = y ~ x, se = FALSE, color = &quot;purple&quot;) + # Adding the regression line scale_y_continuous(limits = c(25, max(CO2$stimmbeteiligungInProzent, na.rm = TRUE))) + # theme_minimal() + labs( x = &quot;Agricultural Area (%)&quot;, y = &quot;Voting Participation (%)&quot;, title = &quot;Scatter plot with Linear Regression Line&quot; ) [Optional] Now add a vertical line with the average for the agricultural area, and a horizontal one with the average turn-out. What does this new graph tell you about the descriptive performance of a regression with and without intercepts? #Means for Y and X mean_AgricAreaPercent &lt;- mean(CO2$AgricAreaPercent, na.rm = TRUE) mean_stimmbeteiligungInProzent &lt;- mean(CO2$stimmbeteiligungInProzent, na.rm = TRUE) # Create a scatter plot ggplot(CO2, aes(x = AgricAreaPercent, y = stimmbeteiligungInProzent)) + geom_point() + geom_smooth(method = &quot;lm&quot;, formula = y ~ x - 1, se = FALSE, color = &quot;red&quot;) + # Adding the regression line geom_smooth(method = &quot;lm&quot;, formula = y ~ x, se = FALSE, color = &quot;purple&quot;) + # Adding the regression line geom_hline(yintercept = mean_stimmbeteiligungInProzent, linetype = &quot;dashed&quot;, color = &quot;green&quot;) + # Horizontal line at the mean of y geom_vline(xintercept = mean_AgricAreaPercent, linetype = &quot;dashed&quot;, color = &quot;orange&quot;) + # Vertical line at the mean of x scale_y_continuous(limits = c(25, max(CO2$stimmbeteiligungInProzent, na.rm = TRUE))) + # theme_minimal() + labs( x = &quot;Agricultural Area (%)&quot;, y = &quot;Voting Participation (%)&quot;, title = &quot;Scatter plot with Linear Regression Line&quot; ) Store the residualas as residuals. Plot the share of agricultural area against the residuals. What does it tell you regarding the ability of the model to describe the central tendency of the relationship across all values of the agricultural land share? residuals1 &lt;- residuals(result1) ggplot(CO2, aes(x = AgricAreaPercent, y = residuals1)) + geom_point() + geom_smooth(method = &quot;lm&quot;, formula = y ~ x , se = TRUE, color = &quot;green&quot;)+ # Adding the theme_minimal() + labs( x = &quot;Agricultural Area (%)&quot;, y = &quot;Residuals (turn-out p.p.)&quot;, title = &quot;Scatter plot with Linear Regression Line&quot; ) [Optional] Repeat the previous point without the intercept. Does the linear regression remains a good tool for describing the central tendency of the relationship across all values of the agricultural land share? residuals0 &lt;- residuals(result0) ggplot(CO2, aes(x = AgricAreaPercent, y = residuals0)) + geom_point() + geom_smooth(method = &quot;lm&quot;, formula = y ~ x , se = TRUE, color = &quot;red&quot;)+ # Adding the theme_minimal() + labs( x = &quot;Agricultural Area (%)&quot;, y = &quot;Residuals (turn-out p.p.)&quot;, title = &quot;Scatter plot with Linear Regression Line&quot; ) 3.4.2 Simulated data You will now simulate the relationship between turn-out and share of agricultural land. Assume the parameters estimated in the last regression (i.e., the \\(\\beta_0\\) and \\(\\beta_1\\)). Retrieve both parameters. coeffs&lt;- coef(result1) print(coeffs) ## (Intercept) AgricAreaPercent ## 55.189867 0.219491 print(unname(coeffs[1]), digits = 5) ## [1] 55.19 print(unname(coeffs[2]), digits = 5) ## [1] 0.21949 Use the parameters to define the assumed data generating process. Assume that the process is deterministic (i.e., it has no stochastic component). Express the equation using mathematical notation. \\[TurnOut_i = \\beta_0 + \\beta_1 * ShareAgriculturalLand\\] Generate a normal distribution that preserves the mean and standard deviation of the original data on share of agricultural land. CO2$Sim_ShareAgric_norm &lt;- rnorm(nrow(CO2), mean = mean_AgricAreaPercent, sd = sd(CO2$AgricAreaPercent)) hist(CO2$Sim_ShareAgric_norm, main=&quot;Histogram of Share of Simulated Agricultural Land&quot;, xlab=&quot;Data Values&quot;, ylab=&quot;Frequency&quot;, col=&quot;blue&quot;, border=&quot;black&quot;) abline(v=mean_AgricAreaPercent, col=&quot;red&quot;, lwd=2, lty=2) Predict the turn-out values given the simulated inputs on the share of agricultural land using the data generating process defined two points above. Graph relation between both variables using a liner regression line. CO2$Pred_TurnOut_Determ &lt;- unname(coeffs[1]) + unname(coeffs[2])*CO2$Sim_ShareAgric_norm ggplot(CO2, aes(x = Sim_ShareAgric_norm, y = Pred_TurnOut_Determ)) + geom_point() + geom_smooth(method = &quot;lm&quot;, formula = y ~ x, se = FALSE, color = &quot;purple&quot;) + # Adding the regression line geom_hline(yintercept = mean_stimmbeteiligungInProzent, linetype = &quot;dashed&quot;, color = &quot;green&quot;) + # Horizontal line at the mean of y geom_vline(xintercept = mean_AgricAreaPercent, linetype = &quot;dashed&quot;, color = &quot;orange&quot;) + # Vertical line at the mean of x scale_y_continuous(limits = c(25, max(CO2$stimmbeteiligungInProzent, na.rm = TRUE))) + # theme_minimal() + labs( x = &quot;Agricultural Area (%)&quot;, y = &quot;Voting Participation (%)&quot;, title = &quot;Simulation: deterministic model&quot; ) Generate a normal distribution with error distribution with mean zero and standard deviation equal to the standard deviation of the residual of the model with intercept. CO2$Sim_resid_norm &lt;- rnorm(nrow(CO2), mean = 0, sd = sd(residuals1)) hist(CO2$Sim_resid_norm, main=&quot;Histogram of Simulated Normal Residuals&quot;, xlab=&quot;Data Values&quot;, ylab=&quot;Frequency&quot;, col=&quot;blue&quot;, border=&quot;black&quot;) abline(v=0, col=&quot;red&quot;, lwd=2, lty=2) Repeat the same model but now add the stochastic element. Graph relation between both variables using a liner regression line. CO2$Pred_TurnOut_Stoch &lt;- CO2$Pred_TurnOut_Determ + CO2$Sim_resid_norm ggplot(CO2, aes(x = Sim_ShareAgric_norm, y = Pred_TurnOut_Stoch)) + geom_point() + geom_smooth(method = &quot;lm&quot;, formula = y ~ x, se = FALSE, color = &quot;purple&quot;) + # Adding the regression line geom_hline(yintercept = mean_stimmbeteiligungInProzent, linetype = &quot;dashed&quot;, color = &quot;green&quot;) + # Horizontal line at the mean of y geom_vline(xintercept = mean_AgricAreaPercent, linetype = &quot;dashed&quot;, color = &quot;orange&quot;) + # Vertical line at the mean of x scale_y_continuous(limits = c(25, max(CO2$Sim_ShareAgric_norm, na.rm = TRUE))) + # theme_minimal() + labs( x = &quot;Agricultural Area (%)&quot;, y = &quot;Voting Participation (%)&quot;, title = &quot;Simulation: deterministic and stochastic model&quot; ) [Optional] Now repeat the same simulation but generating errors that distribute uniformly and lognormally. For the lognormal distribution, use the same mean and standard deviations as in the immediately previous exercises. For the uniform, use the maximum, and minimum values of the residuals for the model with intercept. Uniform simulated residuals: CO2$Sim_resid_unif &lt;- runif(nrow(CO2), min = min(residuals1), max = max(residuals1)) hist(CO2$Sim_resid_unif, main=&quot;Histogram of Simulated Uniform Residuals&quot;, xlab=&quot;Data Values&quot;, ylab=&quot;Frequency&quot;, col=&quot;blue&quot;, border=&quot;black&quot;) abline(v=0, col=&quot;red&quot;, lwd=2, lty=2) Data generating process with uniform residuals: CO2$Pred_TurnOut_Unif &lt;- CO2$Pred_TurnOut_Determ + CO2$Sim_resid_unif ggplot(CO2, aes(x = Sim_ShareAgric_norm, y = Pred_TurnOut_Unif)) + geom_point() + geom_smooth(method = &quot;lm&quot;, formula = y ~ x, se = FALSE, color = &quot;purple&quot;) + geom_hline(yintercept = mean(CO2$Pred_TurnOut_Unif), linetype = &quot;dashed&quot;, color = &quot;green&quot;) + geom_vline(xintercept = mean_AgricAreaPercent, linetype = &quot;dashed&quot;, color = &quot;orange&quot;) + scale_y_continuous(limits = c(25, max(CO2$Pred_TurnOut_Unif, na.rm = TRUE))) + theme_minimal() + labs( x = &quot;Agricultural Area (%)&quot;, y = &quot;Voting Participation (%)&quot;, title = &quot;Simulation: deterministic and stochastic model (uniform error)&quot; ) Lognormal simulated residuals: CO2$Sim_resid_lnorm &lt;- rlnorm(nrow(CO2), mean = 0, sd = sd(residuals1)) hist(CO2$Sim_resid_lnorm, main=&quot;Histogram of Simulated Uniform Residuals&quot;, xlab=&quot;Data Values&quot;, ylab=&quot;Frequency&quot;, col=&quot;blue&quot;, border=&quot;black&quot;) abline(v=0, col=&quot;red&quot;, lwd=2, lty=2) Data generating process with lognormal residuals without adjusting scale of Y: CO2$Pred_TurnOut_Lnorm &lt;- CO2$Pred_TurnOut_Determ + CO2$Sim_resid_lnorm ggplot(CO2, aes(x = Sim_ShareAgric_norm, y = Pred_TurnOut_Lnorm)) + geom_point() + geom_smooth(method = &quot;lm&quot;, formula = y ~ x, se = FALSE, color = &quot;purple&quot;) + geom_hline(yintercept = mean(CO2$Pred_TurnOut_Lnorm), linetype = &quot;dashed&quot;, color = &quot;green&quot;) + geom_vline(xintercept = mean_AgricAreaPercent, linetype = &quot;dashed&quot;, color = &quot;orange&quot;) + scale_y_continuous(limits = c(25, max(CO2$Pred_TurnOut_Lnorm, na.rm = TRUE))) + # theme_minimal() + labs( x = &quot;Agricultural Area (%)&quot;, y = &quot;Voting Participation (%)&quot;, title = &quot;Simulation: deterministic and stochastic model (log normal error)&quot; ) Data generating process with lognormal residuals adjusting scale of Y: CO2$Pred_TurnOut_Lnorm &lt;- CO2$Pred_TurnOut_Determ + CO2$Sim_resid_lnorm ggplot(CO2, aes(x = Sim_ShareAgric_norm, y = Pred_TurnOut_Lnorm)) + geom_point() + scale_y_log10() + geom_smooth(method = &quot;lm&quot;, formula = y ~ x, se = FALSE, color = &quot;purple&quot;) + geom_hline(yintercept = mean(CO2$Pred_TurnOut_Lnorm), linetype = &quot;dashed&quot;, color = &quot;green&quot;) + geom_vline(xintercept = mean_AgricAreaPercent, linetype = &quot;dashed&quot;, color = &quot;orange&quot;) + theme_minimal() + labs( x = &quot;Agricultural Area (%)&quot;, y = &quot;Voting Participation (%) in logarithmic scale&quot;, title = &quot;Simulation: deterministic and stochastic model (log normal error)&quot; ) Ask yourself: does it make sense to have participation values higher than 100%? Parabolic simulated residuals: CO2$parab_norm_resid&lt;- -0.01*(CO2$Sim_ShareAgric_norm-mean(CO2$Sim_ShareAgric_norm))^2+CO2$Sim_resid_norm CO2$parab_norm_resid&lt;- CO2$parab_norm_resid-mean(CO2$parab_norm_resid) ggplot(CO2, aes(x = Sim_ShareAgric_norm, y = parab_norm_resid)) + geom_point() + geom_smooth(method = &quot;lm&quot;, formula = y ~ x, se = FALSE, color = &quot;green&quot;) + theme_minimal() + labs( x = &quot;Agricultural Area (%)&quot;, y = &quot;Error&quot;, title = &quot;Simulation: of parabolic error&quot; ) What does the behavior of the error tell you about the potential reliability of a regression without quadratic terms? Data generating process with parabolic residuals: CO2$Pred_TurnOut_parab_norm_resid &lt;- CO2$Pred_TurnOut_Determ + CO2$parab_norm_resid ggplot(CO2, aes(x = Sim_ShareAgric_norm, y = Pred_TurnOut_parab_norm_resid)) + geom_point() + geom_smooth(method = &quot;lm&quot;, formula = y ~ x, se = FALSE, color = &quot;purple&quot;) + geom_hline(yintercept = mean(CO2$Pred_TurnOut_parab_norm_resid), linetype = &quot;dashed&quot;, color = &quot;green&quot;) + geom_vline(xintercept = mean_AgricAreaPercent, linetype = &quot;dashed&quot;, color = &quot;orange&quot;) + scale_y_continuous(limits = c(25, max(CO2$Pred_TurnOut_Unif, na.rm = TRUE))) + # theme_minimal() + labs( x = &quot;Agricultural Area (%)&quot;, y = &quot;Voting Participation (%)&quot;, title = &quot;Simulation: deterministic and stochastic model (uniform error)&quot; ) Would using a quadratic term in the regression produce a better fit? Graph the regression line with a quadratic term. ggplot(CO2, aes(x = Sim_ShareAgric_norm, y = Pred_TurnOut_parab_norm_resid)) + geom_point() + geom_smooth(method = &quot;lm&quot;, formula = y ~ x + I(x^2), se = FALSE, color = &quot;purple&quot;) + geom_hline(yintercept = mean(CO2$Pred_TurnOut_parab_norm_resid), linetype = &quot;dashed&quot;, color = &quot;green&quot;) + geom_vline(xintercept = mean_AgricAreaPercent, linetype = &quot;dashed&quot;, color = &quot;orange&quot;) + scale_y_continuous(limits = c(25, max(CO2$Pred_TurnOut_Unif, na.rm = TRUE))) + theme_minimal() + labs( x = &quot;Agricultural Area (%)&quot;, y = &quot;Voting Participation (%)&quot;, title = &quot;Simulation: deterministic and stochastic model (uniform error)&quot; ) "],["week-4-regression-ii-model-specification.html", "Chapter 4 Week 4: Regression II (Model Specification) 4.1 Aims 4.2 Exercise: Context and Questions 4.3 Getting the data first 4.4 Exercise: solution 4.5 Interactive Line Plot", " Chapter 4 Week 4: Regression II (Model Specification) 4.1 Aims Using multiple regressors and interaction terms in regression analysis for quantitative descriptive purposes with real data Using simulation to instantiate how different properties of the data generating process alter or not metrics of goodness of fit Should we request them to do descriptive statistics?. Check: are all list numerals fine?. Check: do all parameters in the interpretation texts fine?. 4.2 Exercise: Context and Questions Currently led by Prof. Anke Tresch, “[t]he Swiss Election Study (Selects) has been investigating the electoral behaviour of Swiss citizens in national elections since 1995. The project sheds light on the dynamics of the citizens’ opinion formation as well as on the determinants of their political participation and voting choice for a specific candidate or party.” See more here. In this exercise, you will use data for the year 2019. You will use it to answer the following questions: Do older voters have stronger right leaning preferences than younger ones? age Does that behavior change across sexes? sex Does that behavior change depending on the main language spoken at the respondent’s home? f20221 What about the interaction sex-age? What about the interaction sex-language? What about the interaction age-language? What about the interaction sex-age-language? Do right leaning preferences become stronger the older voters are? 4.3 Getting the data first Opening: # selects19 &lt;- read.csv(&quot;~/Documents/0_IPZ/2023_2/Leemann-QuantMethods/QuantitativeMethods/Data/SELECTS 2019/1179_Selects2019_PES_Data_v1.1.0.csv&quot;, header = TRUE) # # selects19 &lt;- selects19 %&gt;% # select(sex, age, matches(&quot;f15200&quot;), f20221) %&gt;% # filter(!is.na(selects19$sex) &amp; !is.na(selects19$age) &amp; !is.na(selects19$f15200) &amp; !is.na(selects19$f20221)) # Remove rows where x or y is NA # # selects19$f15200 &lt;- as.numeric(selects19$f15200) # # write.table(selects19, file = &quot;~/Documents/0_IPZ/2023_2/Leemann-QuantMethods/QuantitativeMethods/QuantitativeMethods/Data/SELECTS 2019/data.csv&quot;, sep = &quot;,&quot;, row.names = FALSE) selects19 &lt;- read.csv(&quot;~/Documents/0_IPZ/2023_2/Leemann-QuantMethods/QuantitativeMethods/QuantitativeMethods/Data/SELECTS 2019/data.csv&quot;, header = TRUE) Labeling languages: selects19 &lt;- selects19 %&gt;% mutate(LanguageHome = case_when( f20221 == 1 ~ &quot;German/Swiss German&quot;, f20221 == 2 ~ &quot;French&quot;, f20221 == 3 ~ &quot;Italian&quot;, f20221 == 4 ~ &quot;Romansh&quot;, f20221 == 5 ~ &quot;Other&quot;)) Labeling sex: selects19 &lt;- selects19 %&gt;% mutate(Sex = case_when( sex == 1 ~ &quot;Male&quot;, sex == 2 ~ &quot;Female&quot;)) Renaming political preferences: selects19 &lt;- dplyr::rename(selects19, LeftToRight = f15200) 4.4 Exercise: solution Note: Remember that you can copy the code from one point to answer another point. Simply make the necessary adjustments. 4.4.1 Real data Graph age vs. political preferences. Use a linear regression line to describe how the variables relate to each other. #Means for Y and X mean_LeftRight &lt;- mean(selects19$LeftToRight, na.rm = TRUE) mean_age &lt;- mean(selects19$age, na.rm = TRUE) # Create a scatter plot ggplot(selects19, aes(x = age, y = LeftToRight)) + geom_point() + geom_smooth(method = &quot;lm&quot;, formula = y ~ x, se = FALSE, color = &quot;red&quot;) + # Adding the regression line geom_hline(yintercept = mean_LeftRight, linetype = &quot;dashed&quot;, color = &quot;green&quot;) + # Horizontal line at the mean of y geom_vline(xintercept = mean_age, linetype = &quot;dashed&quot;, color = &quot;orange&quot;) + # Vertical line at the mean of x scale_y_continuous( limits = c(0, 10), breaks = seq(0, 10, by = 1)) + theme_minimal() + theme(plot.title = element_text(hjust = 0.5)) + labs( x = &quot;Age (years)&quot;, y = &quot;Political Preferences (left to right)&quot;, title = &quot;Scatter plot Age vs. Political Preferences&quot; ) Since the political preferences as well as years are defined in discrete values, many values can overlap for the same pair(preference, age). Use the ggridges package to see how do preferences distribute across different age values. ggplot(selects19, aes(x = age, y = as.factor(LeftToRight), fill = as.factor(LeftToRight))) + geom_density_ridges() + geom_smooth(data = selects19, aes(x = age, y = LeftToRight, group = 1), method = &quot;lm&quot;, formula = y ~ x, color = &quot;red&quot;, se = FALSE) + geom_hline(yintercept = mean_LeftRight, linetype = &quot;dashed&quot;, color = &quot;green&quot;) + geom_vline(xintercept = mean_age, linetype = &quot;dashed&quot;, color = &quot;orange&quot;) + scale_fill_viridis_d() + theme_minimal() + theme(legend.position = &quot;none&quot;) + theme(plot.title = element_text(hjust = 0.5)) + labs(x = &quot;Age (years)&quot;, y = &quot;Political Preferences (left to right)&quot;, title = &quot;Political preferences by age level&quot;, fill = &quot;factor(LeftToRight)&quot;) Regress the political preferences on age. As we learnt in the exercises from last week, the regression with intercept fits data better in most cases: act accordingly. Report and interpret the parameters. Graph some of the main components of the regression output. Write the regression here. #regression result &lt;- lm(LeftToRight ~ age, data = selects19) summary(result) ## ## Call: ## lm(formula = LeftToRight ~ age, data = selects19) ## ## Residuals: ## Min 1Q Median 3Q Max ## -5.9150 -2.0380 -0.0186 2.1958 5.5271 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 4.122055 0.106375 38.750 &lt;2e-16 *** ## age 0.019489 0.001979 9.846 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 2.649 on 5905 degrees of freedom ## Multiple R-squared: 0.01615, Adjusted R-squared: 0.01598 ## F-statistic: 96.94 on 1 and 5905 DF, p-value: &lt; 2.2e-16 Report and interpret the parameters here. coeffs&lt;- coef(result) cat(&#39;The beta value for&#39;, names(coeffs[1]), &#39; is &#39;, round(unname(coeffs[1]), digits = 2), &#39; and for &#39;, names(coeffs[2]), &#39; is &#39;, round(unname(coeffs[2]), digits = 2), &#39;. \\n\\nIt means that, given our model, an increase of one year in age across the Swiss citizens is associated with an average increase in the LeftToRight self-declared scale of &#39;, round(unname(coeffs[2]), digits = 2), &#39; \\&#39;ideological units\\&#39;. Likewise, newborns can be expected to have an average ideological value of &#39;,round(unname(coeffs[1]), digits = 2),&#39;, while 100 year old citizens can be expected to have an average ideological value of.&#39;, round(unname(coeffs[1]), digits = 2)+round(unname(coeffs[2]), digits = 2)*100) ## The beta value for (Intercept) is 4.12 and for age is 0.02 . ## ## It means that, given our model, an increase of one year in age across the Swiss citizens is associated with an average increase in the LeftToRight self-declared scale of 0.02 &#39;ideological units&#39;. Likewise, newborns can be expected to have an average ideological value of 4.12 , while 100 year old citizens can be expected to have an average ideological value of. 6.12 Graph some of the main components of the regression output here. ggplot(selects19, aes(x = age, y = LeftToRight)) + # Removed selects19$ from aes(), not necessary geom_point(size = 0.001) + geom_abline(intercept = unname(coeffs[1]), slope = 0, color = &quot;gray&quot;, size = 1) + geom_text(aes(label = &quot;Newborn&quot;, x = max(selects19$age)+10, y = 0.2+unname(coeffs[1])), hjust = 1, vjust = 0, color = &quot;gray&quot;)+ geom_abline(intercept = unname(coeffs[1]), slope = unname(coeffs[2]), color = &quot;red&quot;, size = 1) + geom_text(aes(label = &quot;Average individual over time&quot;, x = max(selects19$age)+10, y = 0.4+unname(coeffs[1]) + unname(coeffs[2]) * max(selects19$age)), hjust = 1, vjust = 0, color = &quot;red&quot;) + theme_minimal() + theme(plot.title = element_text(hjust = 0.5)) + labs( x = &quot;Age (years)&quot;, y = &quot;Political Preferences (left to right)&quot;, title = &quot;Lines Using Parameters from Regression&quot; ) Now add the regressor Sex and do the same as in the previous point. Write the regression here. #regression result &lt;- lm(LeftToRight ~ age + Sex, data = selects19) summary(result) ## ## Call: ## lm(formula = LeftToRight ~ age + Sex, data = selects19) ## ## Residuals: ## Min 1Q Median 3Q Max ## -6.2108 -1.9784 0.0954 2.1145 5.8236 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 3.840287 0.109636 35.028 &lt;2e-16 *** ## age 0.018672 0.001966 9.496 &lt;2e-16 *** ## SexMale 0.652678 0.068477 9.531 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 2.629 on 5904 degrees of freedom ## Multiple R-squared: 0.03106, Adjusted R-squared: 0.03073 ## F-statistic: 94.63 on 2 and 5904 DF, p-value: &lt; 2.2e-16 Report and interpret the parameters here. coeffs&lt;- coef(result) cat(&#39;The beta value for&#39;, names(coeffs[1]), &#39; is &#39;, round(unname(coeffs[1]), digits = 2), &#39; for &#39;, names(coeffs[2]), &#39; is &#39;, round(unname(coeffs[2]), digits = 2), &#39; and for &#39;, names(coeffs[3]), &#39; is &#39;, round(unname(coeffs[3]), digits = 2), &#39;. \\n\\nIt means that, given our model, an increase of one year in age across the Swiss citizens is associated with an average increase in the LeftToRight self-declared scale of &#39;, round(unname(coeffs[2]), digits = 2), &#39; \\&#39;ideological units\\&#39;. Likewise, newborns can be expected to have an average ideological value of &#39;,round(unname(coeffs[1]), digits = 2),&#39;, while 100 year old female citizens can be expected to have an average ideological value of.&#39;, round(unname(coeffs[1]), digits = 2)+round(unname(coeffs[2]), digits = 2)*100, &#39;. Similarly, for each of those scenarios, should the individual be a male, it can be expected to have an average of &#39;, round(unname(coeffs[3]), digits = 2), &#39; ideological units higher than a female individual under the same statistical circumstances.&#39;) ## The beta value for (Intercept) is 3.84 for age is 0.02 and for SexMale is 0.65 . ## ## It means that, given our model, an increase of one year in age across the Swiss citizens is associated with an average increase in the LeftToRight self-declared scale of 0.02 &#39;ideological units&#39;. Likewise, newborns can be expected to have an average ideological value of 3.84 , while 100 year old female citizens can be expected to have an average ideological value of. 5.84 . Similarly, for each of those scenarios, should the individual be a male, it can be expected to have an average of 0.65 ideological units higher than a female individual under the same statistical circumstances. Graph some of the main components of the regression output here. ggplot(selects19, aes(x = age, y = LeftToRight)) + # Removed selects19$ from aes(), not necessary geom_point(size = 0.001) + geom_abline(intercept = unname(coeffs[1]), slope = 0, color = &quot;gray&quot;, size = 1) + geom_text(aes(label = &quot;Newborn female&quot;, x = max(selects19$age)+10, y = 0.2+unname(coeffs[1])), hjust = 1, vjust = 0, color = &quot;gray&quot;)+ geom_abline(intercept = unname(coeffs[1]), slope = unname(coeffs[2]), color = &quot;red&quot;, size = 1) + geom_text(aes(label = &quot;Female over time&quot;, x = max(selects19$age)+10, y = -0.8+unname(coeffs[1]) + unname(coeffs[2]) * max(selects19$age)), hjust = 1, vjust = 0, color = &quot;red&quot;) + geom_abline(intercept = unname(coeffs[1])+unname(coeffs[3]), slope = unname(coeffs[2]), color = &quot;orange&quot;, size = 1) + geom_text(aes(label = &quot;Male over time (newborn bonus)&quot;, x = max(selects19$age)+10, y = 0.6+unname(coeffs[1])+unname(coeffs[3]) + unname(coeffs[2]) * max(selects19$age)+0.2), hjust = 1, vjust = 0, color = &quot;orange&quot;) + theme_minimal() + theme(plot.title = element_text(hjust = 0.5)) + labs( x = &quot;Age (years)&quot;, y = &quot;Political Preferences (left to right)&quot;, title = &quot;Lines Using Parameters from Regression&quot; ) You now remember that average preferences can change not only across age and sex independently, but simultaneously: i.e., the average preferences across individuals in a same sex can change at different rates over time as well as begin from different points. Add the interaction Age and Sex and do the same as in the previous point. Write the regression here. #regression result &lt;- lm(LeftToRight ~ age * Sex, data = selects19) summary(result) ## ## Call: ## lm(formula = LeftToRight ~ age * Sex, data = selects19) ## ## Residuals: ## Min 1Q Median 3Q Max ## -5.9332 -2.0641 0.0372 2.1848 6.0372 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 3.506922 0.146203 23.987 &lt; 2e-16 *** ## age 0.025327 0.002756 9.189 &lt; 2e-16 *** ## SexMale 1.340734 0.211254 6.347 2.37e-10 *** ## age:SexMale -0.013528 0.003930 -3.443 0.00058 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 2.626 on 5903 degrees of freedom ## Multiple R-squared: 0.033, Adjusted R-squared: 0.03251 ## F-statistic: 67.15 on 3 and 5903 DF, p-value: &lt; 2.2e-16 Report and interpret the parameters here. coeffs&lt;- coef(result) cat(&#39;The beta value for&#39;, names(coeffs[1]), &#39; is &#39;, round(unname(coeffs[1]), digits = 2), &#39; for &#39;, names(coeffs[2]), &#39; is &#39;, round(unname(coeffs[2]), digits = 2), &#39; for &#39;, names(coeffs[3]), &#39; is &#39;, round(unname(coeffs[3]), digits = 2),&#39; and for &#39;, names(coeffs[4]), &#39; is &#39;, round(unname(coeffs[4]), digits = 2), &#39;. \\n\\nIt means that, given our model, an increase of one year in age across the female Swiss citizens is associated with an average increase in the LeftToRight self-declared scale of &#39;, round(unname(coeffs[2]), digits = 2), &#39; \\&#39;ideological units\\&#39;. Likewise, female newborns can be expected to have an average ideological value of &#39;,round(unname(coeffs[1]), digits = 2),&#39;, while 100 year old female citizens can be expected to have an average ideological value of.&#39;, round(unname(coeffs[1]), digits = 2)+round(unname(coeffs[2]), digits = 2)*100, &#39;. \\n\\nSimilarly, for each of those scenarios, should the individual be a male, it can be expected to have an average of &#39;, round(unname(coeffs[3]), digits = 2), &#39; ideological units higher (i.e., self declare more right leaning) than a female individual under the same statistical circumstances. Finally, the rate at which right leaning prefferences increase over time is &#39;, round(unname(coeffs[4]), digits = 2)*-1, &#39; lower than a female in the same statistical circumstances. Therefore, a 100 year old male can be expected to have an political preference of &#39;, round(unname(coeffs[1]), digits = 2)+round(unname(coeffs[2]), digits = 2)*100+round(unname(coeffs[3]), digits = 2)+round(unname(coeffs[4]), digits = 2)*100) ## The beta value for (Intercept) is 3.51 for age is 0.03 for SexMale is 1.34 and for age:SexMale is -0.01 . ## ## It means that, given our model, an increase of one year in age across the female Swiss citizens is associated with an average increase in the LeftToRight self-declared scale of 0.03 &#39;ideological units&#39;. Likewise, female newborns can be expected to have an average ideological value of 3.51 , while 100 year old female citizens can be expected to have an average ideological value of. 6.51 . ## ## Similarly, for each of those scenarios, should the individual be a male, it can be expected to have an average of 1.34 ideological units higher (i.e., self declare more right leaning) than a female individual under the same statistical circumstances. Finally, the rate at which right leaning prefferences increase over time is 0.01 lower than a female in the same statistical circumstances. Therefore, a 100 year old male can be expected to have an political preference of 6.85 Graph some of the main components of the regression output here. ggplot(selects19, aes(x = age, y = LeftToRight)) + geom_point(size = 0) + geom_abline(intercept = unname(coeffs[1]), slope = 0, color = &quot;gray&quot;, size = 1) + geom_text(aes(label = &quot;Newborn female&quot;, x = max(selects19$age)+10, y = -0.5+unname(coeffs[1])), hjust = 1, vjust = 0, color = &quot;gray&quot;)+ geom_abline(intercept = unname(coeffs[1]), slope = unname(coeffs[2]), color = &quot;red&quot;, size = 1) + geom_text(aes(label = &quot;Female over time&quot;, x = max(selects19$age)+10, y = -0.8+unname(coeffs[1]) + unname(coeffs[2]) * max(selects19$age)), hjust = 1, vjust = 0, color = &quot;red&quot;) + geom_abline(intercept = unname(coeffs[1])+unname(coeffs[3]), slope = unname(coeffs[2])+unname(coeffs[4]), color = &quot;orange&quot;, size = 1) + geom_text(aes(label = &quot;Male over time (newborn bonus+Δslope)&quot;, x = max(selects19$age)+10, y = 0.45+unname(coeffs[1])+unname(coeffs[3]) + (unname(coeffs[2])+unname(coeffs[4])) * max(selects19$age)), hjust = 1, vjust = 0, color = &quot;orange&quot;) + theme_minimal() + theme(plot.title = element_text(hjust = 0.5)) + labs( x = &quot;Age (years)&quot;, y = &quot;Political Preferences (left to right)&quot;, title = &quot;Lines Using Parameters from Regression&quot; ) Following the same logic as in the previous point, you now add the LanguageHome categorical variable with the corresponding interactions. Do the same as in the previous point. Write the regression here. #regression result &lt;- lm(LeftToRight ~ age * Sex * LanguageHome, data = selects19) summary(result) ## ## Call: ## lm(formula = LeftToRight ~ age * Sex * LanguageHome, data = selects19) ## ## Residuals: ## Min 1Q Median 3Q Max ## -6.1650 -2.0129 0.0157 2.0714 6.1504 ## ## Coefficients: ## Estimate Std. Error t value ## (Intercept) 3.4304317 0.2328505 14.732 ## age 0.0232899 0.0043627 5.338 ## SexMale 1.2217711 0.3489102 3.502 ## LanguageHomeGerman/Swiss German 0.0096680 0.3214760 0.030 ## LanguageHomeItalian 1.4371272 0.5006063 2.871 ## LanguageHomeOther -1.1059089 0.6179065 -1.790 ## LanguageHomeRomansh -2.3047615 3.5040694 -0.658 ## age:SexMale -0.0140639 0.0065181 -2.158 ## age:LanguageHomeGerman/Swiss German 0.0053104 0.0060152 0.883 ## age:LanguageHomeItalian -0.0154796 0.0095441 -1.622 ## age:LanguageHomeOther 0.0169430 0.0126468 1.340 ## age:LanguageHomeRomansh 0.0425055 0.0732632 0.580 ## SexMale:LanguageHomeGerman/Swiss German 0.1885585 0.4684575 0.403 ## SexMale:LanguageHomeItalian -0.5629460 0.7043389 -0.799 ## SexMale:LanguageHomeOther 1.6468317 0.9783983 1.683 ## SexMale:LanguageHomeRomansh 1.0259620 4.0396347 0.254 ## age:SexMale:LanguageHomeGerman/Swiss German 0.0002337 0.0086831 0.027 ## age:SexMale:LanguageHomeItalian 0.0124492 0.0133246 0.934 ## age:SexMale:LanguageHomeOther -0.0265266 0.0193016 -1.374 ## age:SexMale:LanguageHomeRomansh 0.0041536 0.0833735 0.050 ## Pr(&gt;|t|) ## (Intercept) &lt; 2e-16 *** ## age 9.73e-08 *** ## SexMale 0.000466 *** ## LanguageHomeGerman/Swiss German 0.976009 ## LanguageHomeItalian 0.004109 ** ## LanguageHomeOther 0.073543 . ## LanguageHomeRomansh 0.510732 ## age:SexMale 0.030994 * ## age:LanguageHomeGerman/Swiss German 0.377368 ## age:LanguageHomeItalian 0.104877 ## age:LanguageHomeOther 0.180393 ## age:LanguageHomeRomansh 0.561819 ## SexMale:LanguageHomeGerman/Swiss German 0.687324 ## SexMale:LanguageHomeItalian 0.424175 ## SexMale:LanguageHomeOther 0.092391 . ## SexMale:LanguageHomeRomansh 0.799525 ## age:SexMale:LanguageHomeGerman/Swiss German 0.978527 ## age:SexMale:LanguageHomeItalian 0.350189 ## age:SexMale:LanguageHomeOther 0.169395 ## age:SexMale:LanguageHomeRomansh 0.960268 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 2.615 on 5887 degrees of freedom ## Multiple R-squared: 0.04377, Adjusted R-squared: 0.04068 ## F-statistic: 14.18 on 19 and 5887 DF, p-value: &lt; 2.2e-16 Report and interpret the parameters here. coeffs &lt;- coef(result) cat(&#39;Interpreting a regression with ever more interactions is exponentially harder! Thus, find below some few cases aimed at signaling the general logic in the interpretation.&#39;, &#39;\\n\\nAn increase of one year in age across the female Swiss citizens is associated with an average increase in the LeftToRight self-declared scale of &#39;, round(unname(coeffs[2]), digits = 2), &#39; \\&#39;ideological units\\&#39;. Likewise, female newborns whose household speaks mainly in French can be expected to have an average ideological value of &#39;,round(unname(coeffs[1]), digits = 2),&#39;, while a 100 year old female citizens whose household speaks mainly in French can be expected to have an average ideological value of.&#39;, round(unname(coeffs[1]), digits = 2)+round(unname(coeffs[2]), digits = 2)*100, &#39;.\\n\\nSimilarly, should one observe a random 100 year old male individual whose household speaks mainly in German, we can expected him have an average of &#39;, round(unname(coeffs[2]), digits = 2)*100+round(unname(coeffs[3]), digits = 2)+round(unname(coeffs[8]), digits = 2)*100+round(unname(coeffs[9]), digits = 2)*100+round(unname(coeffs[13]), digits = 2)+round(unname(coeffs[17]), digits = 2)*100, &#39; ideological units higher than a female newborn whose household speaks mainly in French. Consequently, the expected ideological value for the former would be of &#39;, round(unname(coeffs[1]), digits = 2)+round(unname(coeffs[2]), digits = 2)*100+round(unname(coeffs[3]), digits = 2)+round(unname(coeffs[8]), digits = 2)*100+round(unname(coeffs[9]), digits = 2)*100+round(unname(coeffs[13]), digits = 2)+round(unname(coeffs[17]), digits = 2)*100) ## Interpreting a regression with ever more interactions is exponentially harder! Thus, find below some few cases aimed at signaling the general logic in the interpretation. ## ## An increase of one year in age across the female Swiss citizens is associated with an average increase in the LeftToRight self-declared scale of 0.02 &#39;ideological units&#39;. Likewise, female newborns whose household speaks mainly in French can be expected to have an average ideological value of 3.43 , while a 100 year old female citizens whose household speaks mainly in French can be expected to have an average ideological value of. 5.43 . ## ## Similarly, should one observe a random 100 year old male individual whose household speaks mainly in German, we can expected him have an average of 3.41 ideological units higher than a female newborn whose household speaks mainly in French. Consequently, the expected ideological value for the former would be of 6.84 Graph some of the main components of the regression output here. ggplot(selects19, aes(x = age, y = LeftToRight)) + # Removed selects19$ from aes(), not necessary geom_point(size = 0) + geom_abline(intercept = unname(coeffs[1]), slope = 0, color = &quot;gray&quot;, size = 1) + geom_text(aes(label = &quot;Newborn female French speaking household&quot;, x = max(selects19$age)+10, y = 0.1+unname(coeffs[1])), hjust = 1, vjust = 0, color = &quot;gray&quot;)+ geom_abline(intercept = unname(coeffs[1]), slope = unname(coeffs[2]), color = &quot;red&quot;, size = 1) + geom_text(aes(label = &quot;Female French speaking household over time&quot;, x = max(selects19$age)+10, y = -1.6+unname(coeffs[1]) + unname(coeffs[2]) * max(selects19$age)), hjust = 1, vjust = 0, color = &quot;red&quot;) + geom_abline(intercept = unname(coeffs[1])+unname(coeffs[3]), slope = unname(coeffs[2])+unname(coeffs[8]), color = &quot;orange&quot;, size = 1) + geom_text(aes(label = &quot;Male French household over time (newborn bonus+Δslope)&quot;, x = max(selects19$age)+10, y = 0.4+unname(coeffs[1])+unname(coeffs[3]) + (unname(coeffs[2])+unname(coeffs[8])) * max(selects19$age)+0.2), hjust = 1, vjust = 0, color = &quot;orange&quot;) + geom_abline(intercept = unname(coeffs[1])+unname(coeffs[3])+unname(coeffs[13]), slope = unname(coeffs[2])+unname(coeffs[8])+unname(coeffs[17]), color = &quot;purple&quot;, size = 1) + geom_text(aes(label = &quot;Male German household over time (newborn &amp; ling. bonus+Δslope)&quot;, x = max(selects19$age)+10, y = 1.2+unname(coeffs[1])+unname(coeffs[3])+unname(coeffs[13]) + (unname(coeffs[2])+unname(coeffs[8])+unname(coeffs[17])) * max(selects19$age)+0.2), hjust = 1, vjust = 0, color = &quot;purple&quot;) + # geom_abline(intercept = unname(coeffs[1])+unname(coeffs[3]), # slope = unname(coeffs[2])+unname(coeffs[4]), color = &quot;blue&quot;, size = 1) + # geom_text(aes(label = &quot;Int.(fem)+Male+Age*Male&quot;, # x = max(selects19$age)+10, # y = 0.3+unname(coeffs[1])+unname(coeffs[3]) + (unname(coeffs[2])+unname(coeffs[4])) * max(selects19$age)+0.2), # hjust = 1, vjust = 0, color = &quot;blue&quot;) + theme_minimal() + theme(plot.title = element_text(hjust = 0.5)) + labs( x = &quot;Age (years)&quot;, y = &quot;Political Preferences (left to right)&quot;, title = &quot;Lines Using Parameters from Regression&quot; ) Ojo: Check that interpretations have the right parameters!. 4.5 Interactive Line Plot Should we exploit this here or somewhere else? I can make it work in R, but not in the book yet. If needed, I can check it out.. # # Example data frame # data &lt;- data.frame( # x = rnorm(100), # y = rnorm(100) # ) # # # Shiny server function # server &lt;- function(input, output) { # output$scatterPlot &lt;- renderPlot({ # ggplot(data, aes(x = x, y = y)) + # geom_point(size = 0) + # geom_abline(intercept = input$intercept, slope = input$slope, color = &quot;red&quot;, size = 1) # }) # } # # # Example data frame # data &lt;- data.frame( # x = rnorm(100), # y = rnorm(100) # ) # # # Shiny server function # server &lt;- function(input, output) { # output$scatterPlot &lt;- renderPlot({ # ggplot(data, aes(x = x, y = y)) + # geom_point(size = 0) + # geom_abline(intercept = input$intercept, slope = input$slope, color = &quot;red&quot;, size = 1) # }) # } # # update.packages(ask = FALSE) # # # library(shiny) # library(ggplot2) # # ui &lt;- fluidPage( # titlePanel(&quot;Interactive Line Plot&quot;), # sidebarLayout( # sidebarPanel( # sliderInput(&quot;intercept&quot;, &quot;Intercept:&quot;, min = -10, max = 10, value = 0), # sliderInput(&quot;slope&quot;, &quot;Slope:&quot;, min = -10, max = 10, value = 1) # ), # mainPanel( # plotOutput(&quot;scatterPlot&quot;) # ) # ) # ) # # server &lt;- function(input, output) { # output$scatterPlot &lt;- renderPlot({ # ggplot(data, aes(x = x, y = y)) + # geom_point(size = 0) + # geom_abline(intercept = input$intercept, slope = input$slope, color = &quot;red&quot;, size = 1) # }) # } # # shinyApp(ui = ui, server = server) 4.5.1 Simulated data In order to see the logic behind the \\(R^2\\), first estimate the linear regression of LeftToRight on Age. Generate the variable predicted_LeftToRight with the generated parameters using predict() from the point 3 of the previous section (i.e., the one using real data).Generate the graph predicted_LeftToRight vs Age. Report the regression here. result &lt;- lm(LeftToRight ~ age, data = selects19) selects19$predicted_LeftToRight &lt;- predict(result) coeffs1 &lt;- coef(result) rsq_sd1 &lt;- summary(result)$r.squared cat(&#39;The R2 is: &#39;, rsq_sd1, &#39;\\n\\nIntercept:&#39;,unname(coeffs1[1]), &#39;\\n\\nSlope:&#39;, unname(coeffs1[2])) ## The R2 is: 0.0161515 ## ## Intercept: 4.122055 ## ## Slope: 0.01948902 Report the graph here. # Calculate means for Y and X mean_LeftRight &lt;- mean(selects19$LeftToRight, na.rm = TRUE) mean_age &lt;- mean(selects19$age, na.rm = TRUE) # Create a scatter plot ggplot(selects19, aes(x = age, y = predicted_LeftToRight)) + geom_smooth(method = &quot;lm&quot;, formula = y ~ x, se = FALSE, color = &quot;red&quot;) + # Adding the regression line geom_hline(yintercept = mean_LeftRight, linetype = &quot;dashed&quot;, color = &quot;green&quot;) + # Horizontal line at the mean of y geom_vline(xintercept = mean_age, linetype = &quot;dashed&quot;, color = &quot;orange&quot;) + # Vertical line at the mean of x scale_y_continuous( limits = c(0, 10), breaks = seq(0, 10, by = 1) ) + theme_minimal() + theme( plot.title = element_text(hjust = 0.5), # Center the plot title panel.grid.major.y = element_line(color = &quot;grey80&quot;, size = 0.5), # Style for major Y grid lines panel.grid.minor.y = element_blank() # Remove minor Y grid lines ) + labs( x = &quot;Age (years)&quot;, y = &quot;Political Preferences (left to right)&quot;, title = &quot;Scatter plot Age vs. Political Preferences (determ. sim.)&quot; ) Now generate the normally distributed residuals with mean zero and the same variance as the residuals of the model from the previous point. # Calculate the variance of the residuals selects19$residual &lt;- resid(result) residual_sd &lt;- sqrt(var(resid(result))) # Set the seed for reproducibility set.seed(0) selects19$NormResiduals1 &lt;- rnorm(nrow(selects19), mean = 0, sd = residual_sd) Simulate new data using both the deterministic (i.e., the the parameters estimated immediately above) and stochastic component (i.e., the residuals form the previous point). Graph the simulated data. selects19$Sim_LeftToRight_Det_Stoch &lt;- selects19$predicted_LeftToRight + selects19$NormResiduals1 #Means for Y and X mean_LeftRight &lt;- mean(selects19$Sim_LeftToRight_Det_Stoch, na.rm = TRUE) mean_age &lt;- mean(selects19$age, na.rm = TRUE) # Create a scatter plot ggplot(selects19, aes(x = age, y = Sim_LeftToRight_Det_Stoch)) + geom_point(size = 0) + geom_smooth(method = &quot;lm&quot;, formula = y ~ x, se = FALSE, color = &quot;red&quot;) + # Adding the regression line geom_hline(yintercept = mean_LeftRight, linetype = &quot;dashed&quot;, color = &quot;green&quot;) + # Horizontal line at the mean of y geom_vline(xintercept = mean_age, linetype = &quot;dashed&quot;, color = &quot;orange&quot;) + # Vertical line at the mean of x theme_minimal() + theme(plot.title = element_text(hjust = 0.5)) + scale_y_continuous( limits = c(0, 10), breaks = seq(0, 10, by = 1)) + theme_minimal() + theme( plot.title = element_text(hjust = 0.5), # Center the plot title panel.grid.major.y = element_line(color = &quot;grey80&quot;, size = 0.5), # Style for major Y grid lines panel.grid.minor.y = element_blank() # Remove minor Y grid lines ) + labs( x = &quot;Age (years)&quot;, y = &quot;Simulation: Political Preferences (left to right)&quot;, title = &quot;Scatter plot Age vs. Political Preferences \\n(determ.&amp; stoch. sim.)&quot; ) Now, estimate the regression between the real age and simulated Sim_LeftToRight_Det_Stoch. Once you do that, generate the \\(R^2\\) for the model. result &lt;- lm(LeftToRight ~ age, data = selects19) rsq_sd1 &lt;- summary(result)$r.squared cat(&#39;The R2 is: &#39;, rsq_sd1) ## The R2 is: 0.0161515 Repeat the previous three points but use half the standard deviation of the model of point 1. Is the \\(R^2\\) lower now? Why? See this entry to understand the intuition: pay special attention to the graph with the red and blue squares. Generate the residuals here. # Set the seed for reproducibility set.seed(0) selects19$NormResiduals10 &lt;- rnorm(nrow(selects19), mean = 0, sd = residual_sd*0.1) Simulate new data and graph it here. selects19$Sim_LeftToRight_Det_Stoch_sd10 &lt;- selects19$predicted_LeftToRight + selects19$NormResiduals10 #Means for Y and X mean_LeftRight &lt;- mean(selects19$Sim_LeftToRight_Det_Stoch_sd10, na.rm = TRUE) mean_age &lt;- mean(selects19$age, na.rm = TRUE) # Create a scatter plot ggplot(selects19, aes(x = age, y = Sim_LeftToRight_Det_Stoch_sd10)) + geom_point(size = 0) + geom_smooth(method = &quot;lm&quot;, formula = y ~ x, se = FALSE, color = &quot;red&quot;) + # Adding the regression line geom_hline(yintercept = mean_LeftRight, linetype = &quot;dashed&quot;, color = &quot;green&quot;) + # Horizontal line at the mean of y geom_vline(xintercept = mean_age, linetype = &quot;dashed&quot;, color = &quot;orange&quot;) + # Vertical line at the mean of x scale_y_continuous( limits = c(0, 10), breaks = seq(0, 10, by = 1)) + theme_minimal() + theme(plot.title = element_text(hjust = 0.5)) + labs( x = &quot;Age (years)&quot;, y = &quot;Simulated data (half sd): Political Preferences (left to right)&quot;, title = &quot;Scatter plot Age vs. Political Preferences&quot; ) Report the new \\(R^2\\) here: result &lt;- lm(Sim_LeftToRight_Det_Stoch_sd10 ~ age, data = selects19) rsq_sd10 &lt;- summary(result)$r.squared cat(&#39;The R2 is: &#39;, rsq_sd10) ## The R2 is: 0.625503 Repeat the previous point but use a hundredth the standard deviation of the model of point 1. Is the \\(R^2\\) lower now? Why? Generate the residuals here. # Set the seed for reproducibility set.seed(0) selects19$NormResiduals100 &lt;- rnorm(nrow(selects19), mean = 0, sd = residual_sd*0.01) Simulate new data and graph it here. selects19$Sim_LeftToRight_Det_Stoch_hsd &lt;- selects19$predicted_LeftToRight + selects19$NormResiduals100 #Means for Y and X mean_LeftRight &lt;- mean(selects19$Sim_LeftToRight_Det_Stoch_hsd, na.rm = TRUE) mean_age &lt;- mean(selects19$age, na.rm = TRUE) # Create a scatter plot ggplot(selects19, aes(x = age, y = Sim_LeftToRight_Det_Stoch_hsd)) + geom_point(size = 0) + geom_smooth(method = &quot;lm&quot;, formula = y ~ x, se = FALSE, color = &quot;red&quot;) + # Adding the regression line geom_hline(yintercept = mean_LeftRight, linetype = &quot;dashed&quot;, color = &quot;green&quot;) + # Horizontal line at the mean of y geom_vline(xintercept = mean_age, linetype = &quot;dashed&quot;, color = &quot;orange&quot;) + # Vertical line at the mean of x scale_y_continuous( limits = c(0, 10), breaks = seq(0, 10, by = 1)) + theme_minimal() + theme(plot.title = element_text(hjust = 0.5)) + labs( x = &quot;Age (years)&quot;, y = &quot;Simulated data (half sd): Political Preferences (left to right)&quot;, title = &quot;Scatter plot Age vs. Political Preferences&quot; ) Report the new \\(R^2\\) here: result &lt;- lm(Sim_LeftToRight_Det_Stoch_hsd ~ age, data = selects19) rsq_sd100 &lt;- summary(result)$r.squared cat(&#39;The R2 is: &#39;, rsq_sd100) ## The R2 is: 0.9939772 Present in a table the \\(R^2\\) for each value of the standard deviation. table &lt;- data.frame( SD = c(1, 0.1, 0.01), R2 = c(rsq_sd1, rsq_sd10, rsq_sd100) # Replace these with the actual R-squared values ) print(table) ## SD R2 ## 1 1.00 0.0161515 ## 2 0.10 0.6255030 ## 3 0.01 0.9939772 Graph \\(R^2\\) agains the standard deviation fraction. Fit a linear regression line. ggplot(table, aes(x = SD, y = R2)) + geom_point(size = 0) + geom_smooth(method = &quot;lm&quot;, formula = y ~ x, se = FALSE, color = &quot;green&quot;)+ theme_minimal() + theme(plot.title = element_text(hjust = 0.5)) + labs( x = &quot;Fraction of standard deviation&quot;, y = &quot;R2&quot;, title = &quot;Relation between R2 and standard deviation of residuals&quot; ) 9. [Optional] Graph \\(R^2\\) against the standard deviation fraction. Fit a regression line with a polynomial of degree 2. The regression line fits the data better. Is the polynomial regression more informative than the linear regression? Why? What lesson does this graph give you in terms of the importance of understanding the theoretical relations between variables beyond what an empirical approach could suggest? What does it teach you regarding the tension between under- and over-fitting data? ggplot(table, aes(x = SD, y = R2)) + geom_point() + geom_smooth(method = &quot;lm&quot;, formula = y ~ poly(x, 2), se = FALSE, color=&#39;green&#39;) + theme_minimal() + theme(plot.title = element_text(hjust = 0.5)) + labs( x = &quot;Fraction of standard deviation&quot;, y = &quot;R2&quot;, title = &quot;Relation between R2 and standard deviation of residuals&quot; ) 10. Print the parameters generated in the point 1. Generate the same predictions as in point 1 and 2 but this time multiply the slope’s parameter by 5, while keeping the intercept unchanged. Call the resulting predictions predicted_LeftToRight_AdjSlope Generate a graph with the regression line for predicted_LeftToRight_AdjSlope vs Age and compare it with the graph predicted_LeftToRight vs Age generated in point 1. Print here result &lt;- lm(LeftToRight ~ age, data = selects19) # summary(result) coeffs &lt;- coef(result) cat(&#39;Intercept:&#39;,unname(coeffs[1]), &#39;\\n\\nSlope:&#39;, unname(coeffs[2])) ## Intercept: 4.122055 ## ## Slope: 0.01948902 Predict with the adjusted slope here. selects19$predicted_LeftToRight_AdjSlope &lt;- unname(coeffs[1])+(unname(coeffs[2])*5)*selects19$age Generate the graph here. #Means for Y and X mean_LeftRight &lt;- mean(selects19$predicted_LeftToRight_AdjSlope, na.rm = TRUE) mean_age &lt;- mean(selects19$age, na.rm = TRUE) # Create a scatter plot ggplot(selects19, aes(x = age, y = predicted_LeftToRight_AdjSlope)) + geom_smooth(method = &quot;lm&quot;, formula = y ~ x, se = FALSE, color = &quot;red&quot;) + # Adding the regression line geom_hline(yintercept = mean_LeftRight, linetype = &quot;dashed&quot;, color = &quot;green&quot;) + # Horizontal line at the mean of y geom_vline(xintercept = mean_age, linetype = &quot;dashed&quot;, color = &quot;orange&quot;) + # Vertical line at the mean of x theme_minimal() + theme(plot.title = element_text(hjust = 0.5)) + scale_y_continuous( limits = c(0, 15), breaks = seq(0, 20, by = 1)) + theme_minimal() + theme( plot.title = element_text(hjust = 0.5), # Center the plot title panel.grid.major.y = element_line(color = &quot;grey80&quot;, size = 0.5), # Style for major Y grid lines panel.grid.minor.y = element_blank() # Remove minor Y grid lines ) + labs( x = &quot;Age (years)&quot;, y = &quot;Political Preferences (left to right)&quot;, title = &quot;Scatter plot Age vs. Political Preferences (adj. slope)&quot; ) 11. Add to the deterministic simulation the same stochastic component generated in point 2. Call that variable predicted_LeftToRight_AdjSlope_Stoch. Generate the graph predicted_LeftToRight_AdjSlope_Stoch vs age with a linear regression line. Generate the \\(R^2\\) and compare it to the one generated in point 4. Why is the new \\(R^2\\) higher than the one in point 4? Report the simulation and the graph here. selects19$predicted_LeftToRight_AdjSlope_Stoch &lt;- selects19$predicted_LeftToRight_AdjSlope + selects19$NormResiduals1 #Means for Y and X mean_LeftRight &lt;- mean(selects19$predicted_LeftToRight_AdjSlope_Stoch, na.rm = TRUE) mean_age &lt;- mean(selects19$age, na.rm = TRUE) # Create a scatter plot ggplot(selects19, aes(x = age, y = predicted_LeftToRight_AdjSlope_Stoch)) + geom_point(size = 0) + geom_smooth(method = &quot;lm&quot;, formula = y ~ x, se = FALSE, color = &quot;red&quot;) + # Adding the regression line geom_hline(yintercept = mean_LeftRight, linetype = &quot;dashed&quot;, color = &quot;green&quot;) + # Horizontal line at the mean of y geom_vline(xintercept = mean_age, linetype = &quot;dashed&quot;, color = &quot;orange&quot;) + # Vertical line at the mean of x scale_y_continuous( limits = c(0, 20), breaks = seq(0, 20, by = 1)) + theme_minimal() + theme( plot.title = element_text(hjust = 0.5), # Center the plot title panel.grid.major.y = element_line(color = &quot;grey80&quot;, size = 0.5), # Style for major Y grid lines panel.grid.minor.y = element_blank() # Remove minor Y grid lines ) + labs( x = &quot;Age (years)&quot;, y = &quot;Simulation: Political Preferences (left to right)&quot;, title = &quot;Scatter plot Age vs. Political Preferences \\n(determ.&amp; stoch. sim. with adjusted slope)&quot; ) Report the new \\(R^2\\) here: result &lt;- lm(predicted_LeftToRight_AdjSlope_Stoch ~ age, data = selects19) rsq_sd1_AdjSlope &lt;- summary(result)$r.squared cat(&#39;The R2 is: &#39;, rsq_sd1_AdjSlope) ## The R2 is: 0.2973214 Report why is the new \\(R^2\\) higher than the one in point 4? print(&#39;The reason the R2 increased is that, while the distance from each observation to the regression line remained unchainged (i.e., the residual was kept unchanged), by increasing the slope of the generating process, the average distance between each observation and the average observation increased (i.e., Y\\&#39;s variance increased). See the graph with the red and blue squares mentioned in point 5.&#39;) ## [1] &quot;The reason the R2 increased is that, while the distance from each observation to the regression line remained unchainged (i.e., the residual was kept unchanged), by increasing the slope of the generating process, the average distance between each observation and the average observation increased (i.e., Y&#39;s variance increased). See the graph with the red and blue squares mentioned in point 5.&quot; 333333333333 Print the parameters generated in the point 1. Generate the same predictions as in point 1 and 2 but this time increase in two units the intercept’s parameter (not the slope’s parameter as in the point 10), while keeping the slope unchanged. Call the resulting predictions predicted_LeftToRight_AdjSlope Generate a graph with the regression line for predicted_LeftToRight_AdjSlope vs Age and compare it with the graph predicted_LeftToRight vs Age generated in point 1. Print here result &lt;- lm(predicted_LeftToRight_AdjSlope_Stoch ~ age, data = selects19) # summary(result) coeffs12 &lt;- coef(result) cat(&#39;Intercept:&#39;,unname(coeffs12[1]), &#39;\\n\\nSlope:&#39;, unname(coeffs12[2])) ## Intercept: 4.071965 ## ## Slope: 0.09874777 Predict with the adjusted slope here. selects19$predicted_LeftToRight_AdjIntecept &lt;- unname(coeffs[1]+2)+(unname(coeffs[2]))*selects19$age Generate the graph here. #Means for Y and X mean_LeftRight &lt;- mean(selects19$predicted_LeftToRight_AdjIntecept, na.rm = TRUE) mean_age &lt;- mean(selects19$age, na.rm = TRUE) # Create a scatter plot ggplot(selects19, aes(x = age, y = predicted_LeftToRight_AdjIntecept)) + geom_smooth(method = &quot;lm&quot;, formula = y ~ x, se = FALSE, color = &quot;red&quot;) + # Adding the regression line geom_hline(yintercept = mean_LeftRight, linetype = &quot;dashed&quot;, color = &quot;green&quot;) + # Horizontal line at the mean of y geom_vline(xintercept = mean_age, linetype = &quot;dashed&quot;, color = &quot;orange&quot;) + # Vertical line at the mean of x theme_minimal() + theme(plot.title = element_text(hjust = 0.5)) + scale_y_continuous( limits = c(0, 15), breaks = seq(0, 20, by = 1)) + theme_minimal() + theme( plot.title = element_text(hjust = 0.5), # Center the plot title panel.grid.major.y = element_line(color = &quot;grey80&quot;, size = 0.5), # Style for major Y grid lines panel.grid.minor.y = element_blank() # Remove minor Y grid lines ) + labs( x = &quot;Age (years)&quot;, y = &quot;Political Preferences (left to right)&quot;, title = &quot;Scatter plot Age vs. Political Preferences (adj. slope)&quot; ) 13. Add to the deterministic simulation the same stochastic component generated in point 2. Call that variable predicted_LeftToRight_AdjIntercep_Stoch. Generate the graph predicted_LeftToRight_AdjIntecept vs age with a linear regression line. Generate the \\(R^2\\) and compare it to the one generated in point 4. Why is the new \\(R^2\\) higher than the one in point 4? Report the simulation and the graph here. selects19$predicted_LeftToRight_AdjIntercept_Stoch &lt;- selects19$predicted_LeftToRight_AdjIntecept + selects19$residual #Means for Y and X mean_LeftRight &lt;- mean(selects19$predicted_LeftToRight_AdjIntercept_Stoch, na.rm = TRUE) mean_age &lt;- mean(selects19$age, na.rm = TRUE) # Create a scatter plot ggplot(selects19, aes(x = age, y = predicted_LeftToRight_AdjIntercept_Stoch)) + geom_point(size = 0) + geom_smooth(method = &quot;lm&quot;, formula = y ~ x, se = FALSE, color = &quot;red&quot;) + # Adding the regression line geom_hline(yintercept = mean_LeftRight, linetype = &quot;dashed&quot;, color = &quot;green&quot;) + # Horizontal line at the mean of y geom_vline(xintercept = mean_age, linetype = &quot;dashed&quot;, color = &quot;orange&quot;) + # Vertical line at the mean of x scale_y_continuous( limits = c(0, 20), breaks = seq(0, 20, by = 1)) + theme_minimal() + theme( plot.title = element_text(hjust = 0.5), # Center the plot title panel.grid.major.y = element_line(color = &quot;grey80&quot;, size = 0.5), # Style for major Y grid lines panel.grid.minor.y = element_blank() # Remove minor Y grid lines ) + labs( x = &quot;Age (years)&quot;, y = &quot;Simulation: Political Preferences (left to right)&quot;, title = &quot;Scatter plot Age vs. Political Preferences \\n(determ.&amp; stoch. sim. with adjusted intercept)&quot; ) Regress the predicted_LeftToRight_AdjIntercept_Stoch on age result &lt;- lm(predicted_LeftToRight_AdjIntercept_Stoch ~ age, data = selects19) rsq_sd1_AdjIntercept &lt;- summary(result)$r.squared coeffs13 &lt;- coef(result) cat(&#39;Intercept:&#39;,unname(coeffs13[1]), &#39;\\n\\nSlope:&#39;, unname(coeffs13[2])) ## Intercept: 6.122055 ## ## Slope: 0.01948902 Report the \\(R^2\\) generated in points 2, 11, and 13 here: tableSD1 &lt;- data.frame( LookR2 = c(&#39;Point 2&#39;, &#39;Point 12&#39;, &#39;Point 13&#39;), Model = c(&#39;Unchanged&#39;, &#39;P2 + (slope*5)&#39;, &#39;P2+(intercept+2)&#39;), R2 = c(rsq_sd1, rsq_sd1_AdjSlope, rsq_sd1_AdjIntercept), LookParams = c(&#39;Point 1&#39;, &#39;Point 12&#39;, &#39;Point 13&#39;), Intercept = c(unname(coeffs1[1]), unname(coeffs12[1]), unname(coeffs13[1])), Slope = c(unname(coeffs1[2]), unname(coeffs12[2]), unname(coeffs13[2])) ) print(tableSD1) ## LookR2 Model R2 LookParams Intercept Slope ## 1 Point 2 Unchanged 0.0161515 Point 1 4.122055 0.01948902 ## 2 Point 12 P2 + (slope*5) 0.2973214 Point 12 4.071965 0.09874777 ## 3 Point 13 P2+(intercept+2) 0.0161515 Point 13 6.122055 0.01948902 Comparing the \\(R^2\\) and the parameters across the models of points 1, 2, and 3 answer the following questions: What effect does increasing the slope of the data generating process (while keeping the residuals and intercept unchanged) have on the \\(R^2\\)? print(&#39;The R2 increases as seen in point 11&#39;) ## [1] &quot;The R2 increases as seen in point 11&quot; What effect does increasing the intercept of the data generating process (while keeping the residuals and slope unchanged) have on the \\(R^2\\)? print(&#39;The R2 stays unchanged as the distance from each observation to the regression line remained unchainged (i.e., the residual was kept unchanged) as well as the average distance between each observation and the average observation remained unchainged (i.e., Y\\&#39;s variance was kept unchanged)&#39;) ## [1] &quot;The R2 stays unchanged as the distance from each observation to the regression line remained unchainged (i.e., the residual was kept unchanged) as well as the average distance between each observation and the average observation remained unchainged (i.e., Y&#39;s variance was kept unchanged)&quot; What effect does increasing the slope of the data generating process (while keeping the residuals and intercept unchanged) have on the intercept and slope? print(&#39;It increases the estimated slope and decreases the intercept.&#39;) ## [1] &quot;It increases the estimated slope and decreases the intercept.&quot; What effect does increasing the intercept of the data generating process (while keeping the residuals and slope unchanged) have on the intercept and slope? print(&#39;It keeps the estimated slope unchanged and the estimated intercept is the same as before the adjustment but increases by the same value that the whole data generating process was modified.&#39;) ## [1] &quot;It keeps the estimated slope unchanged and the estimated intercept is the same as before the adjustment but increases by the same value that the whole data generating process was modified.&quot; "],["week-5.html", "Chapter 5 Week 5 5.1 Exercise 5.2 Solution", " Chapter 5 Week 5 5.1 Exercise 5.2 Solution "],["week-6.html", "Chapter 6 Week 6 6.1 Exercise 6.2 Solution", " Chapter 6 Week 6 6.1 Exercise 6.2 Solution "],["week-7.html", "Chapter 7 Week 7 7.1 Exercise 7.2 Solution", " Chapter 7 Week 7 7.1 Exercise 7.2 Solution "],["week-8-causality-iii-observational-data.html", "Chapter 8 Week 8: Causality III (Observational Data) 8.1 Aims 8.2 Exercise", " Chapter 8 Week 8: Causality III (Observational Data) 8.1 Aims Using simulated data to instantiate the logic behind, diff-in-diff and panel data (i.e., within, between, and twoway fixed effects) methods. Using real data to estimate a causal effect using a two’way fixed effects model. 8.2 Exercise 8.2.1 Simulated data The following data is NOT real and is inspired by Ben Lambert’s video on fixed effects (seehere). It’s purpose is simply to illustrate the logic og the fixed effects models. data &lt;- list( City = c(&#39;NYC&#39;, &#39;NYC&#39;, &#39;NYC&#39;, &#39;Boston&#39;, &#39;Boston&#39;, &#39;Boston&#39;, &#39;Amherst&#39;, &#39;Amherst&#39;, &#39;Amherst&#39;), Time = c(1, 2, 3, 1, 2, 3, 1, 2, 3), Unemployment = c(2, 3, 3, 4, 5, 5, 6, 7, 8), Crime = c(5, 6, 9, 3, 4, 7, 1, 2, 3), Treatment = c(0, 0, 1, 0, 0, 1, 0, 0, 0) ) df &lt;- data.frame(data) # Overall averages df &lt;- df %&gt;% mutate(Y_OverallAverage = mean(Crime), X_OverallAverage = mean(Unemployment)) # Within averages df &lt;- df %&gt;% group_by(City) %&gt;% mutate(Y_WithinAverage = mean(Crime), X_WithinAverage = mean(Unemployment)) # Between averages df &lt;- df %&gt;% group_by(Time) %&gt;% mutate(Y_WithinAverage = mean(Crime), X_WithinAverage = mean(Unemployment)) First the basic graph ggplot(df, aes(x = Unemployment, y = Crime)) + geom_point(size = 5) + geom_smooth(method = &quot;lm&quot;, formula = y ~ x, se = FALSE, color = &quot;gray&quot;) + # Adding the regression line scale_y_continuous( limits = c(0, 10), breaks = seq(0, 10, by = 1)) + theme_minimal()+ theme(plot.title = element_text(hjust = 0.5)) + labs(title = &quot;Unemployment vs Crime&quot;, x = &quot;Unemployment&quot;, y = &quot;Crime&quot; ) Now use shapes for distinguishing cities. ggplot(df, aes(x = Unemployment, y = Crime)) + geom_point(aes(shape = factor(City)), size = 5) + # Apply shape by City only to points geom_smooth(method = &quot;lm&quot;, formula = y ~ x, se = FALSE, color = &quot;gray&quot;) + # Regression line for all data scale_y_continuous( limits = c(0, 10), breaks = seq(0, 10, by = 1)) + theme_minimal() + theme(plot.title = element_text(hjust = 0.5)) + labs(title = &quot;Unemployment vs Crime by City and Time&quot;, x = &quot;Unemployment&quot;, y = &quot;Crime&quot;, shape = &quot;City&quot;) Now also use color for distinguishing also periods. ggplot(df, aes(x = Unemployment, y = Crime)) + geom_point(aes(shape = factor(City), color = factor(Time)), size = 5) + # Apply shape by City only to points scale_color_manual(values = c(&quot;yellow&quot;, &quot;orange&quot;, &quot;red&quot;)) + geom_smooth(method = &quot;lm&quot;, formula = y ~ x, se = FALSE, color = &quot;gray&quot;) + # Regression line for all data scale_y_continuous( limits = c(0, 10), breaks = seq(0, 10, by = 1)) + theme_minimal() + theme(plot.title = element_text(hjust = 0.5)) + labs(title = &quot;Unemployment vs Crime by City and Time&quot;, x = &quot;Unemployment&quot;, y = &quot;Crime&quot;, color = &quot;Time&quot;, shape = &quot;City&quot;) All previous regressions are counter intuitive, why?. Now restrict the regression to each city. What does this suggest regarding the ability of linear regression to capture relations between our variables of interest this scenario? Can we use a regression regardless of how we frame it? Is theory important for guiding how the regression is used? If so, in this case, how? ggplot(df, aes(x = Unemployment, y = Crime, color = factor(Time), shape = factor(City))) + geom_point(size = 5) + scale_color_manual(values = c(&quot;red&quot;, &quot;green&quot;, &quot;blue&quot;)) + geom_smooth(method = &quot;lm&quot;, formula = y ~ x, se = FALSE, color = &quot;red&quot;) + # Adding the regression line scale_y_continuous( limits = c(0, 10), breaks = seq(0, 10, by = 1)) + labs(title = &quot;Unemployment vs Crime by City and Time&quot;, x = &quot;Unemployment&quot;, y = &quot;Crime&quot;, color = &quot;Time&quot;, shape = &quot;City&quot;) + theme_minimal() Now, having seen how regressions are theory dependent for defining how they are framed, let’s see how fixed effects work. Assume that the data generating process behind the relation between unemployment and crime is given by the following formula. \\[Y_{it}=\\alpha_{i}+\\beta_{t}+\\gamma_{it}X_{it}+\\epsilon_{it}\\] With \\[t=1, ..., T\\] and \\[i=1, ..., N\\] Where \\(Y_{it}\\) is crime for city \\(i\\) at time \\(t\\), \\(\\alpha_{i}\\) is a time invariant unobservable (or unobserved) factor influencing the levels of crime in city \\(i\\) (i.e., it’s influence is constant across all periods). \\(\\beta_{t}\\) is a city invariant unobservable (or unobserved) factor influencing the levels of crime at period \\(t\\) (i.e., it’s influence is constant across all cities). \\(\\gamma_{it}\\) is the marginal effect of \\(X_{it}\\), the unemployment level at city \\(i\\) in period \\(t\\). Finally, \\(\\epsilon_{it}\\) is the residual for city \\(i\\) in period \\(t\\) Thus, in order to get rid of the time invariant factor, we can implement the following transformation. \\(\\bar{X}_{i.} = \\frac{1}{T}*sum_{t=1}^{T} X_{it}.\\) _{n=1}^{N} a_n $ \\[Y_{it}=\\alpha_{i}+\\beta_{t}+\\gamma_{it}X_{it}+\\epsilon_{it}\\] perhaps showing only the within case is enough? I’m considering to use this paper, particularly page 8. ggplot(df, aes(x = Unemployment, y = Crime, shape = factor(City))) + geom_point(size = 5) + geom_smooth(method = &quot;lm&quot;, formula = y ~ x, se = FALSE) + # Adding the regression line scale_y_continuous( limits = c(0, 10), breaks = seq(0, 10, by = 1)) + labs(title = &quot;Unemployment vs Crime by City and Time&quot;, x = &quot;Unemployment&quot;, y = &quot;Crime&quot;, shape = &quot;City&quot;) + theme_minimal() 8.2.2 Real data df1 &lt;- swissdd::get_nationalvotes(geolevel = &quot;national&quot;, from_date=&quot;2000-03-12&quot;, to_date = &quot;2015-06-14&quot;) df1&lt;- df1 %&gt;% select(&quot;stimmbeteiligungInProzent&quot;,&quot;votedate&quot;) df1 &lt;- dplyr::rename(df1, Y_National_BetweenAverage = stimmbeteiligungInProzent, vote_date = votedate) ballot_days_final &lt;- readRDS(&quot;/Users/fperil/Documents/0_IPZ/2023_2/Leemann-QuantMethods/QuantitativeMethods/QuantitativeMethods/Data/replication/data/ballot_days_final.rds&quot;) ballot_days_final &lt;- inner_join(ballot_days_final, df1, by=&quot;vote_date&quot;) ballot_days_final &lt;- ballot_days_final %&gt;% group_by(muninr) %&gt;% mutate(Y_municipal_WithinAverage = mean(turnout, na.rm = TRUE), X_municipal_WithinAverage = mean(postage, na.rm = TRUE)) ballot_days_final &lt;- ballot_days_final %&gt;% mutate(Y_National_OverallAverage = mean(turnout, na.rm = TRUE), X_National_OverallAverage = mean(postage, na.rm = TRUE)) ballot_days_final &lt;- ballot_days_final %&gt;% group_by(vote_date) %&gt;% mutate(X_National_BetweenAverage = mean(postage, na.rm = TRUE)) ballot_days_final&lt;- ballot_days_final %&gt;% mutate( Y_demeaned_within = turnout-Y_municipal_WithinAverage, Y_demeaned_between = turnout-Y_National_BetweenAverage, Y_double_demeaned = turnout-Y_municipal_WithinAverage-Y_National_BetweenAverage+Y_National_OverallAverage, X_demeaned_within = postage-X_municipal_WithinAverage, X_demeaned_between = postage-X_National_BetweenAverage, X_double_demeaned = postage-X_municipal_WithinAverage-X_National_BetweenAverage+X_National_OverallAverage ) Results: One way fixed effects: within # One way fixed effects: within OW_FE_WI &lt;- lm(Y_demeaned_within ~ X_demeaned_within - 1, data = ballot_days_final) summary(OW_FE_WI) ## ## Call: ## lm(formula = Y_demeaned_within ~ X_demeaned_within - 1, data = ballot_days_final) ## ## Residuals: ## Min 1Q Median 3Q Max ## -37.03 -6.53 -0.03 6.67 53.07 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## X_demeaned_within 1.46 0.15 9.73 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 10.01 on 89319 degrees of freedom ## (1210 observations deleted due to missingness) ## Multiple R-squared: 0.001059, Adjusted R-squared: 0.001048 ## F-statistic: 94.67 on 1 and 89319 DF, p-value: &lt; 2.2e-16 Results: One way fixed effects: between # One way fixed effects: between OW_FE_BE &lt;- lm(Y_demeaned_between ~ X_demeaned_between - 1, data = ballot_days_final) summary(OW_FE_BE) ## ## Call: ## lm(formula = Y_demeaned_between ~ X_demeaned_between - 1, data = ballot_days_final) ## ## Residuals: ## Min 1Q Median 3Q Max ## -32.706 -6.728 -2.224 2.430 48.172 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## X_demeaned_between 1.3944 0.1132 12.32 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 7.553 on 89319 degrees of freedom ## (1210 observations deleted due to missingness) ## Multiple R-squared: 0.001696, Adjusted R-squared: 0.001685 ## F-statistic: 151.8 on 1 and 89319 DF, p-value: &lt; 2.2e-16 Results: Two way fixed effects: between # Two way fixed effects: between TW_FE &lt;- lm(Y_double_demeaned ~ X_double_demeaned - 1, data = ballot_days_final) summary(TW_FE) ## ## Call: ## lm(formula = Y_double_demeaned ~ X_double_demeaned - 1, data = ballot_days_final) ## ## Residuals: ## Min 1Q Median 3Q Max ## -32.706 -6.728 -2.224 2.430 48.172 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## X_double_demeaned 1.3944 0.1132 12.32 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 7.553 on 89319 degrees of freedom ## (1210 observations deleted due to missingness) ## Multiple R-squared: 0.001696, Adjusted R-squared: 0.001685 ## F-statistic: 151.8 on 1 and 89319 DF, p-value: &lt; 2.2e-16 "],["week-9.html", "Chapter 9 Week 9 9.1 Exercise 9.2 Solution", " Chapter 9 Week 9 9.1 Exercise 9.2 Solution "],["week-10.html", "Chapter 10 Week 10 10.1 Exercise 10.2 Solution", " Chapter 10 Week 10 10.1 Exercise 10.2 Solution "],["week-11.html", "Chapter 11 Week 11 11.1 Exercise 11.2 Solution", " Chapter 11 Week 11 11.1 Exercise 11.2 Solution "],["week-12.html", "Chapter 12 Week 12 12.1 Exercise 12.2 Solution", " Chapter 12 Week 12 12.1 Exercise 12.2 Solution "],["week-13.html", "Chapter 13 Week 13 13.1 Exercise 13.2 Solution", " Chapter 13 Week 13 13.1 Exercise 13.2 Solution "],["week-14.html", "Chapter 14 Week 14 14.1 Exercise 14.2 Solution", " Chapter 14 Week 14 14.1 Exercise 14.2 Solution "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
